{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\ProgramData\\anaconda3\\envs\\spd\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\ProgramData\\anaconda3\\envs\\spd\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\ProgramData\\anaconda3\\envs\\spd\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:460: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\ProgramData\\anaconda3\\envs\\spd\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:461: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\ProgramData\\anaconda3\\envs\\spd\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\ProgramData\\anaconda3\\envs\\spd\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Located Cleverhans\n",
      "Located Carlini_nn_robust_attacks\n",
      "Located Keras-deep-learning-models\n",
      "Located MobileNets\n",
      "Located Deepfool/Universal\n",
      "Located DenseNet\n",
      "Located MagNet\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "from  svhn import SVHNDataset\n",
    "from datasets_utils import *\n",
    "from mnist import MNISTDataset\n",
    "from GTSRB_8 import GTSRB8_Dataset\n",
    "from GTSRB_Util_split_MedFilt_Clahe import medfiltering as medfilter\n",
    "from imagenet import ImageNetDataset\n",
    "import itertools\n",
    "from datasets_utils import get_correct_prediction_idx, evaluate_adversarial_examples, calculate_mean_confidence, calculate_accuracy\n",
    "\n",
    "import os\n",
    "import pdb\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "from skimage import img_as_ubyte\n",
    "import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import app\n",
    "from tensorflow.python.platform import flags\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# flags.DEFINE_string('dataset_name', 'GTSRB-8', 'Supported: MNIST, CIFAR-10, ImageNet,GTSRB-8, SVHN.')\n",
    "flags.DEFINE_string('dataset_name', 'GTSRB-8', 'Supported: MNIST, CIFAR-10, ImageNet,GTSRB-8, SVHN.')\n",
    "flags.DEFINE_string('model_name', 'cleverhans', 'Supported: cleverhans, cleverhans_adv_trained and carlini for MNIST; carlini and DenseNet for CIFAR-10;  ResNet50, VGG19, Inceptionv3 and MobileNet for ImageNet; tohinz for SVHN.')\n",
    "flags.DEFINE_boolean('select', True, 'Select correctly classified examples for the experiement.')\n",
    "flags.DEFINE_boolean('balance_sampling', False, 'Select the same number of examples for each class.')\n",
    "flags.DEFINE_boolean('test_mode', False, 'Only select one sample for each class.')\n",
    "flags.DEFINE_integer('nb_examples', 100, 'The number of examples selected for attacks.')\n",
    "flags.DEFINE_string('result_folder', \"results\", 'The output folder for results.')\n",
    "flags.DEFINE_string('attacks',\"FGSM?eps=0.1;BIM?eps=0.1andeps_iter=0.02;JSMA?targeted=next;CarliniL2?targeted=nextandbatch_size=100andmax_iterations=1000;CarliniL2?targeted=nextandbatch_size=100andmax_iterations=1000andconfidence=2\", 'Attack name and parameters in URL style, separated by semicolon.')\n",
    "flags.DEFINE_float('clip', -1, 'L-infinity clip on the adversarial perturbations.')\n",
    "flags.DEFINE_boolean('visualize', True, 'Output the image examples for each attack, enabled by default.')\n",
    "flags.DEFINE_boolean('verbose', False, 'Stdout level. The hidden content will be saved to log files anyway.')\n",
    "# flags.DEFINE_string('detection', '', 'Supported: feature_squeezing.')\n",
    "flags.DEFINE_string('detection', \"FeatureSqueezing?squeezers=bit_depth_1&distance_measure=l1&fpr=0.05;FeatureSqueezing?squeezers=bit_depth_2&distance_measure=l1&fpr=0.05;FeatureSqueezing?squeezers=bit_depth_1,median_filter_2_2&distance_measure=l1&fpr=0.05;\", 'Supported: feature_squeezing.')\n",
    "flags.DEFINE_boolean('detection_train_test_mode', False, 'Split into train/test datasets.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAGS.model_name     = 'cleverhans'\n",
    "FLAGS.dataset_name     = 'GTSRB-8'\n",
    "# FLAGS.model_name       = 'carlini'\n",
    "FLAGS.model_name       = 'densenet'\n",
    "FLAGS.select           = True\n",
    "FLAGS.balance_sampling = True\n",
    "FLAGS.test_mode        = False\n",
    "FLAGS.nb_examples      = 100\n",
    "FLAGS.result_folder    = \"results\"\n",
    "# FLAGS.attacks          =\"carlinili?targeted=next&batch_size=100&max_iterations=1000andconfidence=10;\"\n",
    "# FLAGS.detection        =\"FeatureSqueezing?squeezers=bit_depth_1anddistance_measure=l1andfpr=0.05;\\\n",
    "# FeatureSqueezing?squeezers=bit_depth_2anddistance_measure=l1&fpr=0.05;\\\n",
    "# FeatureSqueezing?squeezers=bit_depth_1,median_filter_2_2&distance_measure=l1&fpr=0.05;\"\n",
    "FLAGS.attacks          =\"fgsm?eps=0.0156;bim?eps=0.008&eps_iter=0.0012;\\\n",
    "carlinili?targeted=next&batch_size=16&confidence=5;carlinili?targeted=ll&batch_size=16&confidence=5;\\\n",
    "deepfool?overshoot=10;\\\n",
    "carlinil2?targeted=next&batch_size=16&max_iterations=1000&confidence=5;\\\n",
    "carlinil2?targeted=ll&batch_size=16&max_iterations=1000&confidence=5;\\\n",
    "carlinil0?targeted=next&batch_size=16&confidence=5;\\\n",
    "carlinil0?targeted=ll&batch_size=16&confidence=5;\\\n",
    "jsma?targeted=next;\\\n",
    "jsma?targeted=ll\"\n",
    "# FLAGS.attacks         = \"FGSM?eps=0.0156\"\n",
    "# FLAGS.attacks         = \"FGSM?eps=0.1;BIM?eps=0.1&eps_iter=0.02;JSMA?targeted=next;CarliniL2?targeted=next&batch_size=100&max_iterations=1000;\"\n",
    "# FLAGS.attacks         = \"fgsm?eps=0.0156;bim?eps=0.008&eps_iter=0.0012;carlinili?targeted=next&confidence=5;carlinili?targeted=ll&confidence=5;deepfool?overshoot=10;carlinil2?targeted=next&batch_size=100&max_iterations=1000&confidence=5;carlinil2?targeted=ll&batch_size=100&max_iterations=1000&confidence=5;carlinil0?targeted=next&confidence=5;carlinil0?targeted=ll&confidence=5;jsma?targeted=next;jsma?targeted=ll;\"\n",
    "# FLAGS.attacks         = \"fgsm?eps=0.0156;bim?eps=0.008&eps_iter=0.0012\"\n",
    "\n",
    "# FLAGS.detection = \\\n",
    "# \"FeatureSqueezing?squeezers=bit_depth_1&distance_measure=l1&fpr=0.05;\\\n",
    "# FeatureSqueezing?squeezers=bit_depth_2&distance_measure=l1&fpr=0.05;\\\n",
    "# FeatureSqueezing?squeezers=bit_depth_3&distance_measure=l1&fpr=0.05;\\\n",
    "# FeatureSqueezing?squeezers=bit_depth_4&distance_measure=l1&fpr=0.05;\\\n",
    "# FeatureSqueezing?squeezers=bit_depth_5&distance_measure=l1&fpr=0.05;\\\n",
    "# FeatureSqueezing?squeezers=median_filter_2_2&distance_measure=l1&fpr=0.05;\\\n",
    "# FeatureSqueezing?squeezers=median_filter_3_3&distance_measure=l1&fpr=0.05;\\\n",
    "# FeatureSqueezing?squeezers=non_local_means_color_11_3_2&distance_measure=l1&fpr=0.05;\\\n",
    "# FeatureSqueezing?squeezers=non_local_means_color_11_3_4&distance_measure=l1&fpr=0.05;\\\n",
    "# FeatureSqueezing?squeezers=non_local_means_color_13_3_2&distance_measure=l1&fpr=0.05;\\\n",
    "# FeatureSqueezing?squeezers=non_local_means_color_13_3_4&distance_measure=l1&fpr=0.05;\\\n",
    "# FeatureSqueezing?squeezers=bit_depth_5,median_filter_2_2,non_local_means_color_13_3_2&distance_measure=l1&fpr=0.05;\\\n",
    "# FeatureSqueezing?squeezers=bit_depth_5,median_filter_2_2,non_local_means_color_13_3_4&distance_measure=l1&fpr=0.05;\\\n",
    "# FeatureSqueezing?squeezers=bit_depth_5,median_filter_2_2,non_local_means_color_11_3_4&distance_measure=l1&fpr=0.05;\"\n",
    "# FLAGS.detection = \"FeatureSqueezing?squeezers=bit_depth_1&distance_measure=l1&fpr=0.05;\"\n",
    "\n",
    "FLAGS.detection = \\\n",
    "\"FeatureSqueezing?squeezers=bit_depth_5,median_filter_3_3,non_local_means_color_13_3_2&distance_measure=l1&fpr=0.05;\\\n",
    "FeatureSqueezing?squeezers=bit_depth_5,median_filter_3_3,non_local_means_color_13_3_4&distance_measure=l1&fpr=0.05;\\\n",
    "FeatureSqueezing?squeezers=bit_depth_5,median_filter_3_3,non_local_means_color_11_3_4&distance_measure=l1&fpr=0.05;\"\n",
    "# FLAGS.clip             = -1\n",
    "FLAGS.visualize        = True\n",
    "FLAGS.verbose          = False\n",
    "\n",
    "def load_tf_session():\n",
    "    # Set TF random seed to improve reproducibility\n",
    "    tf.set_random_seed(1234)\n",
    "\n",
    "    # Create TF session and set as Keras backend session\n",
    "    sess = tf.Session()\n",
    "    keras.backend.set_session(sess)\n",
    "    print(\"Created TensorFlow session and set Keras backend.\")\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===Loading GTSRB-8 data...\n",
      "Created TensorFlow session and set Keras backend.\n",
      "Model created\n",
      "\n",
      "===Defined TensorFlow model graph.\n",
      "---Loaded GTSRB_8-densenet model.\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 64, 64, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "initial_conv2D (Conv2D)          (None, 64, 64, 16)    432         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 64, 64, 16)    64          initial_conv2D[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 64, 64, 16)    0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 64, 64, 12)    1728        activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 64, 64, 28)    0           initial_conv2D[0][0]             \n",
      "                                                                   conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 64, 64, 28)    112         concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 64, 64, 28)    0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 64, 64, 12)    3024        activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 64, 64, 40)    0           concatenate_1[0][0]              \n",
      "                                                                   conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 64, 64, 40)    160         concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 64, 64, 40)    0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 64, 64, 12)    4320        activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 64, 64, 52)    0           concatenate_2[0][0]              \n",
      "                                                                   conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 64, 64, 52)    208         concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 64, 64, 52)    0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 64, 64, 12)    5616        activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 64, 64, 64)    0           concatenate_3[0][0]              \n",
      "                                                                   conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 64, 64, 64)    256         concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 64, 64, 64)    0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 64, 64, 12)    6912        activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 64, 64, 76)    0           concatenate_4[0][0]              \n",
      "                                                                   conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 64, 64, 76)    304         concatenate_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 64, 64, 76)    0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 64, 64, 12)    8208        activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)      (None, 64, 64, 88)    0           concatenate_5[0][0]              \n",
      "                                                                   conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 64, 64, 88)    352         concatenate_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 64, 64, 88)    0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 64, 64, 12)    9504        activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)      (None, 64, 64, 100)   0           concatenate_6[0][0]              \n",
      "                                                                   conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 64, 64, 100)   400         concatenate_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 64, 64, 100)   0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 64, 64, 12)    10800       activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)      (None, 64, 64, 112)   0           concatenate_7[0][0]              \n",
      "                                                                   conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 64, 64, 112)   448         concatenate_8[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 64, 64, 112)   0           batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 64, 64, 12)    12096       activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)      (None, 64, 64, 124)   0           concatenate_8[0][0]              \n",
      "                                                                   conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 64, 64, 124)   496         concatenate_9[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 64, 64, 124)   0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 64, 64, 12)    13392       activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)     (None, 64, 64, 136)   0           concatenate_9[0][0]              \n",
      "                                                                   conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, 64, 64, 136)   544         concatenate_10[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 64, 64, 136)   0           batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 64, 64, 12)    14688       activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)     (None, 64, 64, 148)   0           concatenate_10[0][0]             \n",
      "                                                                   conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, 64, 64, 148)   592         concatenate_11[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 64, 64, 148)   0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 64, 64, 12)    15984       activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)     (None, 64, 64, 160)   0           concatenate_11[0][0]             \n",
      "                                                                   conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, 64, 64, 160)   640         concatenate_12[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 64, 64, 160)   0           batch_normalization_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 64, 64, 160)   25600       activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePool (None, 32, 32, 160)   0           conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, 32, 32, 160)   640         average_pooling2d_1[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 32, 32, 160)   0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 32, 32, 12)    17280       activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)     (None, 32, 32, 172)   0           average_pooling2d_1[0][0]        \n",
      "                                                                   conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNor (None, 32, 32, 172)   688         concatenate_13[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 32, 32, 172)   0           batch_normalization_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 32, 32, 12)    18576       activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)     (None, 32, 32, 184)   0           concatenate_13[0][0]             \n",
      "                                                                   conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, 32, 32, 184)   736         concatenate_14[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 32, 32, 184)   0           batch_normalization_16[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 32, 32, 12)    19872       activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)     (None, 32, 32, 196)   0           concatenate_14[0][0]             \n",
      "                                                                   conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, 32, 32, 196)   784         concatenate_15[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 32, 32, 196)   0           batch_normalization_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 32, 32, 12)    21168       activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)     (None, 32, 32, 208)   0           concatenate_15[0][0]             \n",
      "                                                                   conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, 32, 32, 208)   832         concatenate_16[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 32, 32, 208)   0           batch_normalization_18[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, 32, 32, 12)    22464       activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)     (None, 32, 32, 220)   0           concatenate_16[0][0]             \n",
      "                                                                   conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, 32, 32, 220)   880         concatenate_17[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 32, 32, 220)   0           batch_normalization_19[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 32, 32, 12)    23760       activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)     (None, 32, 32, 232)   0           concatenate_17[0][0]             \n",
      "                                                                   conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, 32, 32, 232)   928         concatenate_18[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 32, 32, 232)   0           batch_normalization_20[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 32, 32, 12)    25056       activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)     (None, 32, 32, 244)   0           concatenate_18[0][0]             \n",
      "                                                                   conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, 32, 32, 244)   976         concatenate_19[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 32, 32, 244)   0           batch_normalization_21[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, 32, 32, 12)    26352       activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)     (None, 32, 32, 256)   0           concatenate_19[0][0]             \n",
      "                                                                   conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, 32, 32, 256)   1024        concatenate_20[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 32, 32, 256)   0           batch_normalization_22[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, 32, 32, 12)    27648       activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)     (None, 32, 32, 268)   0           concatenate_20[0][0]             \n",
      "                                                                   conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, 32, 32, 268)   1072        concatenate_21[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 32, 32, 268)   0           batch_normalization_23[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 32, 32, 12)    28944       activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)     (None, 32, 32, 280)   0           concatenate_21[0][0]             \n",
      "                                                                   conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, 32, 32, 280)   1120        concatenate_22[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 32, 32, 280)   0           batch_normalization_24[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, 32, 32, 12)    30240       activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)     (None, 32, 32, 292)   0           concatenate_22[0][0]             \n",
      "                                                                   conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNor (None, 32, 32, 292)   1168        concatenate_23[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 32, 32, 292)   0           batch_normalization_25[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, 32, 32, 12)    31536       activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)     (None, 32, 32, 304)   0           concatenate_23[0][0]             \n",
      "                                                                   conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNor (None, 32, 32, 304)   1216        concatenate_24[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 32, 32, 304)   0           batch_normalization_26[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, 32, 32, 304)   92416       activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePool (None, 16, 16, 304)   0           conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNor (None, 16, 16, 304)   1216        average_pooling2d_2[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 16, 16, 304)   0           batch_normalization_27[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, 16, 16, 12)    32832       activation_27[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)     (None, 16, 16, 316)   0           average_pooling2d_2[0][0]        \n",
      "                                                                   conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNor (None, 16, 16, 316)   1264        concatenate_25[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 16, 16, 316)   0           batch_normalization_28[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, 16, 16, 12)    34128       activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)     (None, 16, 16, 328)   0           concatenate_25[0][0]             \n",
      "                                                                   conv2d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNor (None, 16, 16, 328)   1312        concatenate_26[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, 16, 16, 328)   0           batch_normalization_29[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, 16, 16, 12)    35424       activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)     (None, 16, 16, 340)   0           concatenate_26[0][0]             \n",
      "                                                                   conv2d_29[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNor (None, 16, 16, 340)   1360        concatenate_27[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, 16, 16, 340)   0           batch_normalization_30[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, 16, 16, 12)    36720       activation_30[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)     (None, 16, 16, 352)   0           concatenate_27[0][0]             \n",
      "                                                                   conv2d_30[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNor (None, 16, 16, 352)   1408        concatenate_28[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, 16, 16, 352)   0           batch_normalization_31[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)               (None, 16, 16, 12)    38016       activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)     (None, 16, 16, 364)   0           concatenate_28[0][0]             \n",
      "                                                                   conv2d_31[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNor (None, 16, 16, 364)   1456        concatenate_29[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 16, 16, 364)   0           batch_normalization_32[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)               (None, 16, 16, 12)    39312       activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)     (None, 16, 16, 376)   0           concatenate_29[0][0]             \n",
      "                                                                   conv2d_32[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNor (None, 16, 16, 376)   1504        concatenate_30[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, 16, 16, 376)   0           batch_normalization_33[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)               (None, 16, 16, 12)    40608       activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)     (None, 16, 16, 388)   0           concatenate_30[0][0]             \n",
      "                                                                   conv2d_33[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNor (None, 16, 16, 388)   1552        concatenate_31[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, 16, 16, 388)   0           batch_normalization_34[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)               (None, 16, 16, 12)    41904       activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)     (None, 16, 16, 400)   0           concatenate_31[0][0]             \n",
      "                                                                   conv2d_34[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNor (None, 16, 16, 400)   1600        concatenate_32[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, 16, 16, 400)   0           batch_normalization_35[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)               (None, 16, 16, 12)    43200       activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)     (None, 16, 16, 412)   0           concatenate_32[0][0]             \n",
      "                                                                   conv2d_35[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNor (None, 16, 16, 412)   1648        concatenate_33[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, 16, 16, 412)   0           batch_normalization_36[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)               (None, 16, 16, 12)    44496       activation_36[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)     (None, 16, 16, 424)   0           concatenate_33[0][0]             \n",
      "                                                                   conv2d_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNor (None, 16, 16, 424)   1696        concatenate_34[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_37 (Activation)       (None, 16, 16, 424)   0           batch_normalization_37[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)               (None, 16, 16, 12)    45792       activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)     (None, 16, 16, 436)   0           concatenate_34[0][0]             \n",
      "                                                                   conv2d_37[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNor (None, 16, 16, 436)   1744        concatenate_35[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_38 (Activation)       (None, 16, 16, 436)   0           batch_normalization_38[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)               (None, 16, 16, 12)    47088       activation_38[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)     (None, 16, 16, 448)   0           concatenate_35[0][0]             \n",
      "                                                                   conv2d_38[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNor (None, 16, 16, 448)   1792        concatenate_36[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_39 (Activation)       (None, 16, 16, 448)   0           batch_normalization_39[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glob (None, 448)           0           activation_39[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 8)             3592        global_average_pooling2d_1[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "activation_40 (Activation)       (None, 8)             0           dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1,036,920\n",
      "Trainable params: 1,018,824\n",
      "Non-trainable params: 18,096\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Defining the dataset\n",
    "if FLAGS.dataset_name == \"GTSRB-8\":\n",
    "    dataset = GTSRB8_Dataset()\n",
    "\n",
    "\n",
    "# 1. Load a dataset.\n",
    "print(\"\\n===Loading %s data...\" % FLAGS.dataset_name)\n",
    "\n",
    "if FLAGS.dataset_name == 'ImageNet':\n",
    "    if FLAGS.model_name == 'inceptionv3':\n",
    "        img_size = 299\n",
    "    else:\n",
    "        img_size = 224\n",
    "    X_test_all, Y_test_all = dataset.get_test_data(img_size, 0, 200)\n",
    "else:\n",
    "    X_test_all, Y_test_all = dataset.get_test_dataset()\n",
    "\n",
    "# 2. Load a trained model.\n",
    "\n",
    "sess1 = load_tf_session()\n",
    "keras.backend.set_learning_phase(0)\n",
    "# Define input TF placeholder\n",
    "x = tf.placeholder(tf.float32, shape=(None, dataset.image_size, dataset.image_size, dataset.num_channels))\n",
    "y = tf.placeholder(tf.float32, shape=(None, dataset.num_classes))\n",
    "\n",
    "with tf.variable_scope(FLAGS.model_name):\n",
    "    \"\"\"\n",
    "    Create a model instance for prediction.\n",
    "    The scaling argument, 'input_range_type': {1: [0,1], 2:[-0.5, 0.5], 3:[-1, 1]...}\n",
    "    \"\"\"\n",
    "    model = dataset.load_model_by_name(FLAGS.model_name, logits=False, input_range_type=1)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='sgd', metrics=['acc'])\n",
    "model.summary()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the pre-trained model...\n",
      "Test accuracy on raw legitimate examples 0.9682\n",
      "Mean confidence on ground truth classes 0.9186\n"
     ]
    }
   ],
   "source": [
    "# 3. Evaluate the trained model.\n",
    "print (\"Evaluating the pre-trained model...\")\n",
    "Y_pred_all    = model.predict(X_test_all)\n",
    "mean_conf_all = calculate_mean_confidence(Y_pred_all, Y_test_all)\n",
    "accuracy_all  = calculate_accuracy(Y_pred_all, Y_test_all)\n",
    "print('Test accuracy on raw legitimate examples %.4f' % (accuracy_all))\n",
    "print('Mean confidence on ground truth classes %.4f' % (mean_conf_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = 3\n",
    "plt.subplot(121)\n",
    "plt.title(\"class {}\".format(Y_test_all[ind]))\n",
    "plt.imshow(X_test_all[ind] )\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 96 examples.\n",
      "Selected index in test set (sorted): 0-29:1,31-54:1,56-59:1,61,65,66,68-71:1,73,75,76,78,81,83,86,90-92:1,95,105,107,115,127,132,138,156,170,177,192,542,1317,1377,1634,1726,1764,1957,1971,2068,2152\n",
      "Test accuracy on selected legitimate examples 1.0000\n",
      "Mean confidence on ground truth classes, selected 0.9133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Select some examples to attack.\n",
    "import hashlib\n",
    "from datasets_utils import get_first_n_examples_id_each_class\n",
    "\n",
    "if FLAGS.select:\n",
    "    # Filter out the misclassified examples.\n",
    "    correct_idx = get_correct_prediction_idx(Y_pred_all, Y_test_all)\n",
    "    if FLAGS.test_mode:\n",
    "        # Only select the first example of each class.\n",
    "        correct_and_selected_idx = get_first_n_examples_id_each_class(Y_test_all[correct_idx])\n",
    "        selected_idx = [ correct_idx[i] for i in correct_and_selected_idx ]\n",
    "    else:\n",
    "        if not FLAGS.balance_sampling:\n",
    "            selected_idx = correct_idx[:FLAGS.nb_examples]\n",
    "        else:\n",
    "            # select the same number of examples for each class label.\n",
    "            nb_examples_per_class = int(FLAGS.nb_examples / Y_test_all.shape[1])\n",
    "            correct_and_selected_idx = get_first_n_examples_id_each_class(Y_test_all[correct_idx], n=nb_examples_per_class)\n",
    "            selected_idx = [ correct_idx[i] for i in correct_and_selected_idx ]\n",
    "else:\n",
    "    selected_idx = np.array(range(FLAGS.nb_examples))\n",
    "\n",
    "from utils.output import format_number_range\n",
    "selected_example_idx_ranges = format_number_range(sorted(selected_idx))\n",
    "print ( \"Selected %d examples.\" % len(selected_idx))\n",
    "print ( \"Selected index in test set (sorted): %s\" % selected_example_idx_ranges )\n",
    "X_test, Y_test, Y_pred = X_test_all[selected_idx], Y_test_all[selected_idx], Y_pred_all[selected_idx]\n",
    "\n",
    "# The accuracy should be 100%.\n",
    "accuracy_selected = calculate_accuracy(Y_pred, Y_test)\n",
    "mean_conf_selected = calculate_mean_confidence(Y_pred, Y_test)\n",
    "print('Test accuracy on selected legitimate examples %.4f' % (accuracy_selected))\n",
    "print('Mean confidence on ground truth classes, selected %.4f\\n' % (mean_conf_selected))\n",
    "\n",
    "task = {}\n",
    "task['dataset_name'] = FLAGS.dataset_name\n",
    "task['model_name'] = FLAGS.model_name\n",
    "task['accuracy_test'] = accuracy_all\n",
    "task['mean_confidence_test'] = mean_conf_all\n",
    "\n",
    "task['test_set_selected_length'] = len(selected_idx)\n",
    "task['test_set_selected_idx_ranges'] = selected_example_idx_ranges\n",
    "task['test_set_selected_idx_hash'] = hashlib.sha1(str(selected_idx).encode('utf-8')).hexdigest()\n",
    "task['accuracy_test_selected'] = accuracy_selected\n",
    "task['mean_confidence_test_selected'] = mean_conf_selected\n",
    "\n",
    "task_id = \"%s_%d_%s_%s\" % \\\n",
    "        (task['dataset_name'], task['test_set_selected_length'], task['test_set_selected_idx_hash'][:5], task['model_name'])\n",
    "\n",
    "FLAGS.result_folder = os.path.join(FLAGS.result_folder, task_id)\n",
    "if not os.path.isdir(FLAGS.result_folder):\n",
    "    print(\"Making the Folder %s\" % FLAGS.result_folder)\n",
    "    os.makedirs(FLAGS.result_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Generate adversarial examples.\n",
    "from attacks import maybe_generate_adv_examples\n",
    "from utils.squeeze import reduce_precision_py\n",
    "from utils.parameter_parser import parse_params\n",
    "attack_string_hash = hashlib.sha1(FLAGS.attacks.encode('utf-8')).hexdigest()[:5]\n",
    "sample_string_hash = task['test_set_selected_idx_hash'][:5]\n",
    "\n",
    "from datasets_utils import get_next_class, get_least_likely_class\n",
    "Y_test_target_next = get_next_class(Y_test)\n",
    "Y_test_target_ll = get_least_likely_class(Y_pred)\n",
    "\n",
    "X_test_adv_list = []\n",
    "X_test_adv_discretized_list = []\n",
    "Y_test_adv_discretized_pred_list = []\n",
    "\n",
    "attack_string_list = filter(lambda x:len(x)>0, FLAGS.attacks.lower().split(';'))\n",
    "to_csv = []\n",
    "\n",
    "X_adv_cache_folder = os.path.join(FLAGS.result_folder, 'adv_examples')\n",
    "adv_log_folder = os.path.join(FLAGS.result_folder, 'adv_logs')\n",
    "predictions_folder = os.path.join(FLAGS.result_folder, 'predictions')\n",
    "for folder in [X_adv_cache_folder, adv_log_folder, predictions_folder]:\n",
    "    if not os.path.isdir(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "predictions_fpath = os.path.join(predictions_folder, \"legitimate.npy\")\n",
    "np.save(predictions_fpath, Y_pred, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack_names_extracted = []\n",
    "# attack_string_list  = filter(lambda x:len(x)>0, FLAGS.attacks.lower().split(';'))\n",
    "# for attack_string in attack_string_list:\n",
    "#     attack_name, attack_params = parse_params(attack_string)\n",
    "#     print ( \"\\nRunning attack: %s %s\" % (attack_name, attack_params))\n",
    "#     attack_names_extracted.append(attack_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running attack: fgsm {'eps': 0.0156}\n",
      "Loading adversarial examples from [GTSRB-8_96_8dfa8_densenet_fgsm_eps=0.0156.pickle].\n",
      "\n",
      "---Attack (uint8): fgsm?eps=0.0156\n",
      "Success rate: 77.08%, Mean confidence of SAEs: 95.60%\n",
      "### Statistics of the SAEs:\n",
      "L2 dist: 1.7321, Li dist: 0.0157, L0 dist_value: 99.5%, L0 dist_pixel: 100.0%\n",
      "\n",
      "Running attack: bim {'eps': 0.008, 'eps_iter': 0.0012}\n",
      "Loading adversarial examples from [GTSRB-8_96_8dfa8_densenet_bim_eps=0.008&eps_iter=0.0012.pickle].\n",
      "\n",
      "---Attack (uint8): bim?eps=0.008&eps_iter=0.0012\n",
      "Success rate: 86.46%, Mean confidence of SAEs: 97.73%\n",
      "### Statistics of the SAEs:\n",
      "L2 dist: 0.7518, Li dist: 0.0078, L0 dist_value: 93.5%, L0 dist_pixel: 99.9%\n",
      "\n",
      "Running attack: carlinili {'targeted': 'next', 'batch_size': 16, 'confidence': 5.0}\n",
      "targeted value: next\n",
      "Loading adversarial examples from [GTSRB-8_96_8dfa8_densenet_carlinili_targeted=next&batch_size=16&confidence=5.pickle].\n",
      "\n",
      "---Attack (uint8): carlinili?targeted=next&batch_size=16&confidence=5\n",
      "Success rate: 100.00%, Mean confidence of SAEs: 98.19%\n",
      "### Statistics of the SAEs:\n",
      "L2 dist: 1.0885, Li dist: 0.0152, L0 dist_value: 82.6%, L0 dist_pixel: 96.6%\n",
      "\n",
      "Running attack: carlinili {'targeted': 'll', 'batch_size': 16, 'confidence': 5.0}\n",
      "targeted value: ll\n",
      "Loading adversarial examples from [GTSRB-8_96_8dfa8_densenet_carlinili_targeted=ll&batch_size=16&confidence=5.pickle].\n",
      "\n",
      "---Attack (uint8): carlinili?targeted=ll&batch_size=16&confidence=5\n",
      "Success rate: 100.00%, Mean confidence of SAEs: 97.73%\n",
      "### Statistics of the SAEs:\n",
      "L2 dist: 1.3666, Li dist: 0.0183, L0 dist_value: 88.7%, L0 dist_pixel: 98.5%\n",
      "\n",
      "Running attack: deepfool {'overshoot': 10.0}\n",
      "Loading adversarial examples from [GTSRB-8_96_8dfa8_densenet_deepfool_overshoot=10.pickle].\n",
      "\n",
      "---Attack (uint8): deepfool?overshoot=10\n",
      "Success rate: 100.00%, Mean confidence of SAEs: 89.46%\n",
      "### Statistics of the SAEs:\n",
      "L2 dist: 0.6788, Li dist: 0.0763, L0 dist_value: 99.0%, L0 dist_pixel: 99.9%\n",
      "\n",
      "Running attack: carlinil2 {'targeted': 'next', 'batch_size': 16, 'max_iterations': 1000, 'confidence': 5.0}\n",
      "targeted value: next\n",
      "Loading adversarial examples from [GTSRB-8_96_8dfa8_densenet_carlinil2_targeted=next&batch_size=16&max_iterations=1000&confidence=5.pickle].\n",
      "\n",
      "---Attack (uint8): carlinil2?targeted=next&batch_size=16&max_iterations=1000&confidence=5\n",
      "Success rate: 100.00%, Mean confidence of SAEs: 98.13%\n",
      "### Statistics of the SAEs:\n",
      "L2 dist: 0.5990, Li dist: 0.0642, L0 dist_value: 28.7%, L0 dist_pixel: 41.5%\n",
      "\n",
      "Running attack: carlinil2 {'targeted': 'll', 'batch_size': 16, 'max_iterations': 1000, 'confidence': 5.0}\n",
      "targeted value: ll\n",
      "Loading adversarial examples from [GTSRB-8_96_8dfa8_densenet_carlinil2_targeted=ll&batch_size=16&max_iterations=1000&confidence=5.pickle].\n",
      "\n",
      "---Attack (uint8): carlinil2?targeted=ll&batch_size=16&max_iterations=1000&confidence=5\n",
      "Success rate: 100.00%, Mean confidence of SAEs: 97.55%\n",
      "### Statistics of the SAEs:\n",
      "L2 dist: 0.8389, Li dist: 0.0723, L0 dist_value: 42.5%, L0 dist_pixel: 59.0%\n",
      "\n",
      "Running attack: carlinil0 {'targeted': 'next', 'batch_size': 16, 'confidence': 5.0}\n",
      "targeted value: next\n",
      "Loading adversarial examples from [GTSRB-8_96_8dfa8_densenet_carlinil0_targeted=next&batch_size=16&confidence=5.pickle].\n",
      "\n",
      "---Attack (uint8): carlinil0?targeted=next&batch_size=16&confidence=5\n",
      "Success rate: 100.00%, Mean confidence of SAEs: 98.22%\n",
      "### Statistics of the SAEs:\n",
      "L2 dist: 2.9054, Li dist: 0.6711, L0 dist_value: 1.0%, L0 dist_pixel: 1.0%\n",
      "\n",
      "Running attack: carlinil0 {'targeted': 'll', 'batch_size': 16, 'confidence': 5.0}\n",
      "targeted value: ll\n",
      "Loading adversarial examples from [GTSRB-8_96_8dfa8_densenet_carlinil0_targeted=ll&batch_size=16&confidence=5.pickle].\n",
      "\n",
      "---Attack (uint8): carlinil0?targeted=ll&batch_size=16&confidence=5\n",
      "Success rate: 100.00%, Mean confidence of SAEs: 97.94%\n",
      "### Statistics of the SAEs:\n",
      "L2 dist: 4.0889, Li dist: 0.7282, L0 dist_value: 2.4%, L0 dist_pixel: 2.4%\n",
      "\n",
      "Running attack: jsma {'targeted': 'next'}\n",
      "targeted value: next\n",
      "Loading adversarial examples from [GTSRB-8_96_8dfa8_densenet_jsma_targeted=next.pickle].\n",
      "\n",
      "---Attack (uint8): jsma?targeted=next\n",
      "Success rate: 100.00%, Mean confidence of SAEs: 38.69%\n",
      "### Statistics of the SAEs:\n",
      "L2 dist: 6.5389, Li dist: 0.8846, L0 dist_value: 0.9%, L0 dist_pixel: 2.3%\n",
      "\n",
      "Running attack: jsma {'targeted': 'll'}\n",
      "targeted value: ll\n",
      "Loading adversarial examples from [GTSRB-8_96_8dfa8_densenet_jsma_targeted=ll.pickle].\n",
      "\n",
      "---Attack (uint8): jsma?targeted=ll\n",
      "Success rate: 96.88%, Mean confidence of SAEs: 34.65%\n",
      "### Statistics of the SAEs:\n",
      "L2 dist: 10.7205, Li dist: 0.9170, L0 dist_value: 2.1%, L0 dist_pixel: 5.2%\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.clip >= 0:\n",
    "    epsilon = FLAGS.clip\n",
    "    print (\"Clip the adversarial perturbations by +-%f\" % epsilon)\n",
    "    max_clip = np.clip(X_test + epsilon, 0, 1)\n",
    "    min_clip = np.clip(X_test - epsilon, 0, 1)\n",
    "attack_string_list = filter(lambda x:len(x)>0, FLAGS.attacks.lower().split(';'))\n",
    "for attack_string in attack_string_list:\n",
    "    attack_log_fpath = os.path.join(adv_log_folder, \"%s_%s.log\" % (task_id, attack_string.replace(\"?\",\"_\")))\n",
    "    attack_name, attack_params = parse_params(attack_string)\n",
    "    print ( \"\\nRunning attack: %s %s\" % (attack_name, attack_params))\n",
    "\n",
    "    if 'targeted' in attack_params:\n",
    "        targeted = attack_params['targeted']\n",
    "        print (\"targeted value: %s\" % targeted)\n",
    "        if targeted == 'next':\n",
    "            Y_test_target = Y_test_target_next\n",
    "        elif targeted == 'll':\n",
    "            Y_test_target = Y_test_target_ll\n",
    "        elif targeted == False:\n",
    "            attack_params['targeted'] = False\n",
    "            Y_test_target = Y_test.copy()\n",
    "    else:\n",
    "        targeted = False\n",
    "        attack_params['targeted'] = False\n",
    "        Y_test_target = Y_test.copy()\n",
    "\n",
    "    x_adv_fname = \"%s_%s.pickle\" % (task_id, attack_string.replace(\"?\",\"_\"))\n",
    "    x_adv_fpath = os.path.join(X_adv_cache_folder, x_adv_fname)\n",
    "\n",
    "    X_test_adv, aux_info = maybe_generate_adv_examples(sess1, model, x, y, X_test, Y_test_target, attack_name, attack_params,\n",
    "                                                        use_cache = x_adv_fpath, verbose=FLAGS.verbose, attack_log_fpath=attack_log_fpath)\n",
    "\n",
    "    if FLAGS.clip > 0:\n",
    "        # This is L-inf clipping.\n",
    "        X_test_adv = np.clip(X_test_adv, min_clip, max_clip)\n",
    "\n",
    "    X_test_adv_list.append(X_test_adv)\n",
    "\n",
    "    if isinstance(aux_info, float):\n",
    "        duration = aux_info\n",
    "    else:\n",
    "        duration = aux_info['duration']\n",
    "\n",
    "    dur_per_sample = duration / len(X_test_adv)\n",
    "\n",
    "    # 5.0 Output predictions.\n",
    "    Y_test_adv_pred = model.predict(X_test_adv)\n",
    "    predictions_fpath = os.path.join(predictions_folder, \"%s.npy\"% attack_string.replace(\"?\",\"_\"))\n",
    "    np.save(predictions_fpath, Y_test_adv_pred, allow_pickle=False)\n",
    "\n",
    "    # 5.1 Evaluate the adversarial examples being discretized to uint8.\n",
    "    print (\"\\n---Attack (uint8): %s\" % attack_string)\n",
    "    # All data should be discretized to uint8.\n",
    "    X_test_adv_discret = reduce_precision_py(X_test_adv, 256)\n",
    "    X_test_adv_discretized_list.append(X_test_adv_discret)\n",
    "    Y_test_adv_discret_pred = model.predict(X_test_adv_discret)\n",
    "    Y_test_adv_discretized_pred_list.append(Y_test_adv_discret_pred)\n",
    "\n",
    "    rec = evaluate_adversarial_examples(X_test, Y_test, X_test_adv_discret, Y_test_target.copy(), targeted, Y_test_adv_discret_pred)\n",
    "    rec['dataset_name'] = FLAGS.dataset_name\n",
    "    rec['model_name'] = FLAGS.model_name\n",
    "    rec['attack_string'] = attack_string.replace(\"?\",\"_\")\n",
    "    rec['duration_per_sample'] = dur_per_sample\n",
    "    rec['discretization'] = True\n",
    "    to_csv.append(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.output import write_to_csv\n",
    "# attacks_evaluation_csv_fpath = os.path.join(FLAGS.result_folder, \n",
    "#         \"%s_attacks_%s_evaluation.csv\" % \\\n",
    "#         (task_id, attack_string_hash))\n",
    "# fieldnames = ['dataset_name', 'model_name', 'attack_string', 'duration_per_sample', 'discretization', 'success_rate', 'mean_confidence', 'mean_l2_dist', 'mean_li_dist', 'mean_l0_dist_value', 'mean_l0_dist_pixel']\n",
    "# write_to_csv(to_csv, attacks_evaluation_csv_fpath, fieldnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pdb\n",
    "import sklearn\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from feature_squeezing import FeatureSqueezingDetector\n",
    "from magnet_mnist import MagNetDetector as MagNetDetectorMNIST\n",
    "from magnet_cifar import MagNetDetector as MagNetDetectorCIFAR\n",
    "\n",
    "from tensorflow.python.platform import flags\n",
    "FLAGS = flags.FLAGS\n",
    "from utils.output import write_to_csv\n",
    "from Segmentation_detector import SegmentationDetector \n",
    "\n",
    "def get_tpr_fpr(true_labels, pred_labels):\n",
    "    TP = np.sum(np.logical_and(pred_labels == 1, true_labels == 1))\n",
    "    FP = np.sum(np.logical_and(pred_labels == 1, true_labels == 0))\n",
    "\n",
    "    AP = np.sum(true_labels)\n",
    "    AN = np.sum(1-true_labels)\n",
    "\n",
    "    tpr = TP/AP if AP>0 else np.nan\n",
    "    fpr = FP/AN if AN>0 else np.nan\n",
    "\n",
    "    return tpr, fpr, TP, AP\n",
    "\n",
    "\n",
    "def evalulate_detection_test(Y_detect_test, Y_detect_pred):\n",
    "    accuracy = sklearn.metrics.accuracy_score(Y_detect_test, Y_detect_pred, normalize=True, sample_weight=None)\n",
    "    tpr, fpr, tp, ap = get_tpr_fpr(Y_detect_test, Y_detect_pred)\n",
    "    return accuracy, tpr, fpr, tp, ap\n",
    "\n",
    "\n",
    "from tinydb import TinyDB, Query\n",
    "\n",
    "class DetectionEvaluator:\n",
    "    \"\"\"\n",
    "    Get a dataset;\n",
    "        Failed adv as benign / Failed adv as adversarial.\n",
    "    For each detector:\n",
    "        Train\n",
    "        Test\n",
    "        Report performance\n",
    "            Detection rate on each attack.\n",
    "            Detection on SAEs / FAEs.\n",
    "            ROC-AUC.\n",
    "\n",
    "    A detector should have this simplified interface:\n",
    "        Y_pred = detector(X)\n",
    "    \"\"\"\n",
    "    def __init__(self, model, result_folder, csv_fname, dataset_name):\n",
    "        pass\n",
    "        # set_base_model()\n",
    "        self.model = model\n",
    "        self.task_dir = result_folder\n",
    "        self.csv_fpath = os.path.join(result_folder, csv_fname)\n",
    "        print(self.csv_fpath)\n",
    "        self.dataset_name = dataset_name\n",
    "\n",
    "        if not os.path.isdir(self.task_dir):\n",
    "            os.makedirs(self.task_dir)\n",
    "\n",
    "    def get_attack_id(self, attack_name):\n",
    "        return self.attack_name_id[attack_name]\n",
    "\n",
    "    def build_detection_dataset(self, X, Y_label, Y_pred, selected_idx, X_adv_list, Y_adv_pred_list,\n",
    "                                 attack_names, attack_string_hash, clip, Y_test_target_next, Y_test_target_ll):\n",
    "        # X_train, Y_train, X_test, Y_test, test_idx, failed_adv_idx = \\\n",
    "        #     get_detection_train_test_set(X, Y_label, X_adv_list, Y_adv_pred_list, attack_names)\n",
    "\n",
    "        \"\"\"\n",
    "        Data Model:\n",
    "            index, attack_id, misclassified, train\n",
    "            14,     0,           0,             1\n",
    "        \"\"\"\n",
    "\n",
    "        self.attack_names = attack_names.lower().split(';')\n",
    "        self.attack_name_id = {}\n",
    "        self.attack_name_id['legitimate'] = 0\n",
    "        # attack_names = filter(lambda x:len(x)>0, attack_names.lower().split(';'))\n",
    "        attack_names = attack_names.lower().split(';')\n",
    "        for i,attack_name in enumerate(attack_names):\n",
    "            # print(\"AttackNames\",i,attack_name)\n",
    "            self.attack_name_id[attack_name] = i+1\n",
    "            # print(self.attack_name_id[attack_name])\n",
    "\n",
    "        X_adv_all = np.concatenate(X_adv_list)\n",
    "        X_leg_all = X[:len(X_adv_all)]\n",
    "        # print(len(X_leg_all),\"kkkkkkk\")\n",
    "        self.X_detect = X_detect = np.concatenate([X_leg_all, X_adv_all])\n",
    "        # TODO: this could be wrong in non-default data selection mode.\n",
    "        Y_label_adv = Y_label[selected_idx]\n",
    "\n",
    "        detection_db_path = os.path.join(self.task_dir, \"detection_db_%s_clip_%s.json\" % (attack_string_hash, clip))\n",
    "\n",
    "        if os.path.isfile(detection_db_path):\n",
    "            self.db = TinyDB(detection_db_path)\n",
    "            self.query = Query()\n",
    "            print (\"Loaded an existing detection dataset.\")\n",
    "            return\n",
    "        else:\n",
    "            print (\"Preparing the detection dataset...\")\n",
    "\n",
    "        # 1. Split Train and Test \n",
    "        random.seed(1234)\n",
    "        length = len(X_detect)\n",
    "        train_ratio = 0.5\n",
    "        train_idx = random.sample(range(length), int(train_ratio*length))\n",
    "        train_test_seq = [1 if idx in train_idx else 0 for idx in range(length) ]\n",
    "\n",
    "        # 2. Tag the misclassified examples, both legitimate and adversarial.\n",
    "        # TODO: Differentiate the successful examples between targeted and non-targeted.\n",
    "        misclassified_seq = list(np.argmax(Y_label[:len(X_leg_all)], axis=1) != np.argmax(Y_pred[:len(X_leg_all)], axis=1))\n",
    "        for Y_adv_pred in Y_adv_pred_list:\n",
    "            misclassified_seq_adv = list(np.argmax(Y_adv_pred, axis=1) != np.argmax(Y_label_adv, axis=1))\n",
    "            misclassified_seq += misclassified_seq_adv\n",
    "\n",
    "        success_adv_seq = [False] * len(X_leg_all)\n",
    "        for ( Y_adv_pred),(attack_name_i) in zip(Y_adv_pred_list,attack_names):\n",
    "            attack_name = attack_name_i\n",
    "            if 'targeted=ll' in attack_name:\n",
    "                # print(\"Yes LL\")\n",
    "                success_adv_seq_attack = list(np.argmax(Y_adv_pred, axis=1) == np.argmax(Y_test_target_ll, axis=1))\n",
    "            elif 'targeted=next' in attack_name:\n",
    "                # print(\"Yes Next\")\n",
    "                success_adv_seq_attack = list(np.argmax(Y_adv_pred, axis=1) == np.argmax(Y_test_target_next, axis=1))\n",
    "            else:\n",
    "                # The same as misclassified.\n",
    "                success_adv_seq_attack = list(np.argmax(Y_adv_pred, axis=1) != np.argmax(Y_label_adv, axis=1))\n",
    "            success_adv_seq += success_adv_seq_attack\n",
    "\n",
    "\n",
    "\n",
    "        # 3. Tag the attack ID, 0 as legitimate.\n",
    "        attack_id_seq = [0]*len(X_leg_all)\n",
    "        # attack_id_seq = [0]*len(X_detect)\n",
    "        # print(\"Hello_Hi\")\n",
    "        # print(len(attack_names),len(attack_id_seq))\n",
    "        for i,attack_name in enumerate(attack_names):\n",
    "            attack_id_seq += [i+1]*len(X_adv_list[0])\n",
    "            # print(\"Hello_friend\")\n",
    "        # print(len(X_detect) , len(train_test_seq) , len(misclassified_seq) , len(attack_id_seq))\n",
    "        assert len(X_detect) == len(train_test_seq) == len(misclassified_seq) == len(attack_id_seq)\n",
    "        # assert len(X_detect) == len(train_test_seq) == len(misclassified_seq)\n",
    "\n",
    "        self.db = TinyDB(detection_db_path)\n",
    "        self.query = Query()\n",
    "        # print(len(attack_id_seq),len(X_detect))\n",
    "        for i in range(len(X_detect)):\n",
    "            attack_id = attack_id_seq[i]\n",
    "            misclassified = 1 if misclassified_seq[i] == True else 0\n",
    "            success = 1 if success_adv_seq[i] == True else 0\n",
    "            train = train_test_seq[i]\n",
    "            rec = {'index': i, 'attack_id': attack_id, 'misclassified': misclassified, 'success': success, 'train': train}\n",
    "            self.db.insert(rec)\n",
    "\n",
    "    def get_data_from_db_records(self, recs):\n",
    "        if len(recs) == 0:\n",
    "            return None, None\n",
    "        X_idx = [rec['index'] for rec in recs]\n",
    "        X = self.X_detect[np.array(X_idx)]\n",
    "        Y = np.array([1 if rec['attack_id']>0 else 0 for rec in recs])\n",
    "        return X, Y\n",
    "\n",
    "    def get_training_testing_data(self, train = True):\n",
    "        db = self.db\n",
    "        query = self.query\n",
    "\n",
    "        recs = db.search(query.train == 1)\n",
    "        X_train, Y_train = self.get_data_from_db_records(recs)\n",
    "\n",
    "        recs = db.search(query.train == 0)\n",
    "        X_test, Y_test = self.get_data_from_db_records(recs)\n",
    "\n",
    "        return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "    def get_adversarial_data(self, only_testing, success, attack_name=None, include_legitimate=False):\n",
    "        db = self.db\n",
    "        query = self.query\n",
    "\n",
    "        conditions_and = []\n",
    "        if only_testing:\n",
    "            conditions_and.append(query.train == 0)\n",
    "\n",
    "        if attack_name is None:\n",
    "            conditions_and.append(query.attack_id > 0)\n",
    "            # print(query.attack_id,\"1\")\n",
    "        else:\n",
    "            # print(attack_name,\"2\")\n",
    "            attack_id = self.get_attack_id(attack_name)\n",
    "            conditions_and.append(query.attack_id == attack_id)\n",
    "\n",
    "        if success:\n",
    "            conditions_and.append(query.success == 1)\n",
    "        else:\n",
    "            conditions_and.append(query.success == 0)\n",
    "\n",
    "        conditions = reduce(lambda a,b:a&b, conditions_and)\n",
    "        print (\"conditions: %s \" % conditions)\n",
    "\n",
    "        recs = db.search(conditions)\n",
    "\n",
    "        if include_legitimate:\n",
    "            if only_testing:\n",
    "                conditions = (query.attack_id == 0) & (query.train == 0)\n",
    "            else:\n",
    "                conditions = query.attack_id == 0\n",
    "            # print (\"additional conditions: %s \" % conditions)\n",
    "            recs += db.search(conditions)\n",
    "\n",
    "        return self.get_data_from_db_records(recs)\n",
    "\n",
    "    def get_sae_testing_data(self, attack_name=None):\n",
    "        return self.get_adversarial_data(only_testing=True, success=True, attack_name=attack_name)\n",
    "\n",
    "    def get_sae_data(self, attack_name=None):\n",
    "        return self.get_adversarial_data(only_testing=False, success=True, attack_name=attack_name)\n",
    "\n",
    "    def get_fae_testing_data(self, attack_name=None):\n",
    "        return self.get_adversarial_data(only_testing=True, success=False, attack_name=attack_name)\n",
    "\n",
    "    def get_fae_data(self, attack_name=None):\n",
    "        return self.get_adversarial_data(only_testing=False, success=False, attack_name=attack_name)\n",
    "\n",
    "    def get_all_non_fae_testing_data(self, attack_name=None):\n",
    "        return self.get_adversarial_data(only_testing=True, success=True, attack_name=attack_name, include_legitimate=True)\n",
    "\n",
    "    def get_all_non_fae_data(self, attack_name=None):\n",
    "        return self.get_adversarial_data(only_testing=False, success=True, attack_name=attack_name, include_legitimate=True)\n",
    "\n",
    "    def get_detector_by_name(self, detector_name):\n",
    "        model = self.model\n",
    "        detector = None\n",
    "\n",
    "        if detector_name.startswith('FeatureSqueezing'):\n",
    "            detector = FeatureSqueezingDetector(model, detector_name)\n",
    "        elif detector_name.startswith('Segmentation'):\n",
    "            detector = SegmentationDetector()\n",
    "        elif detector_name.startswith('MagNet'):\n",
    "            if self.dataset_name == 'MNIST':\n",
    "                detector = MagNetDetectorMNIST(model, detector_name)\n",
    "            elif self.dataset_name == \"CIFAR-10\":\n",
    "                detector = MagNetDetectorCIFAR(model, detector_name)\n",
    "\n",
    "        return detector\n",
    "\n",
    "    def evaluate_detections(self, params_str,X_test_all,Y_test_all):\n",
    "        X_train, Y_train, X_test, Y_test = self.get_training_testing_data()\n",
    "        # print(Y_test)\n",
    "        # Example: --detection \"FeatureSqueezing?distance_measure=l1&squeezers=median_smoothing_2,bit_depth_4;\"\n",
    "        detector_names = [ele.strip() for ele in params_str.split(';') if ele.strip()!= '']\n",
    "        dataset_name = self.dataset_name\n",
    "        csv_fpath = \"./segmentation_detection_%s_saes.csv\" % dataset_name \n",
    "        fieldnames = ['detector', 'threshold', 'fpr','fpr_all_test_clean','Accuracy_all_test_clean'] + list(self.attack_names) + ['overall']\n",
    "        print(fieldnames)\n",
    "        to_csv = []\n",
    "\n",
    "        for detector_name in detector_names:\n",
    "            detector = self.get_detector_by_name(detector_name)\n",
    "            if detector is None:\n",
    "                print (\"Skipped an unknown detector [%s]\" % detector_name.split('?')[0])\n",
    "                continue\n",
    "            detector.train(X_train, Y_train)\n",
    "            Y_test_pred, Y_test_pred_score = detector.test(X_test)\n",
    "            # print( \"Hello Boy\" )\n",
    "            accuracy, tpr, fpr, tp, ap = evalulate_detection_test(Y_test, Y_test_pred)\n",
    "            fprs, tprs, thresholds = roc_curve(Y_test, Y_test_pred_score)\n",
    "            roc_auc = auc(fprs, tprs)\n",
    "            print( \"\\n\" )\n",
    "            print (\"Detector: %s\" % detector_name)\n",
    "            print( \"\\n\" )\n",
    "            print (\"Accuracy: %f\\tTPR: %f\\tFPR: %f\\tROC-AUC: %f\" % (accuracy, tpr, fpr, roc_auc))\n",
    "\n",
    "            Y_test_pred_t, Y_test_pred_score_t = detector.test(X_test_all)\n",
    "            # print(Y_test_pred_t[0], \"Hello Boy\" )\n",
    "            Y_test_thresh = np.zeros(np.array(np.argmax(Y_test_all,axis=1)).shape) \n",
    "            accuracy_all, tpr_all, fpr_all, tp_all, ap_all = evalulate_detection_test(Y_test_thresh, Y_test_pred_t)\n",
    "            print(\"Accuracy_all_test:%.3f\" % accuracy_all,\" FPR_all_test:%.3f\" % fpr_all,\"For all TestSet\")\n",
    "            \n",
    "            rec = {}\n",
    "            rec['detector'] = detector_name\n",
    "            if hasattr(detector, 'threshold'):\n",
    "                rec['threshold'] = detector.threshold\n",
    "            else:\n",
    "                rec['threshold'] = None\n",
    "            rec['fpr'] = fpr\n",
    "            rec['Accuracy_all_test_clean'] = accuracy_all\n",
    "            rec['fpr_all_test_clean'] = fpr_all\n",
    "            overall_detection_rate_saes = 0\n",
    "            nb_saes = 0\n",
    "            for attack_name in self.attack_names:\n",
    "                print( \"\\n\" )\n",
    "                # No adversarial examples for training for the current detection methods.\n",
    "                # X_sae, Y_sae = self.get_sae_testing_data(attack_name)\n",
    "                if FLAGS.detection_train_test_mode:\n",
    "                    print(attack_name)\n",
    "                    X_sae, Y_sae = self.get_sae_testing_data(attack_name)\n",
    "                else:\n",
    "                    X_sae, Y_sae = self.get_sae_data(attack_name)\n",
    "                Y_test_pred, Y_test_pred_score = detector.test(X_sae)\n",
    "                # print(Y_sae,Y_test_pred,\"Hala Madrid\")\n",
    "                _, tpr, _, tp, ap = evalulate_detection_test(Y_sae, Y_test_pred)\n",
    "                print (\"Detection rate on SAEs: %.4f \\t %3d/%3d \\t %s\" % (tpr, tp, ap, attack_name))\n",
    "                overall_detection_rate_saes += tpr * len(Y_sae)\n",
    "                nb_saes += len(Y_sae)\n",
    "                rec[attack_name] = tpr\n",
    "                # print (\"overall_detection_rate_saes/nb_saes: %d/%d\" % (overall_detection_rate_saes, nb_saes))\n",
    "            # print(len(nb_saes))\n",
    "            print(nb_saes)\n",
    "            print (\"Overall detection rate on SAEs: %f (%d/%d)\" % (overall_detection_rate_saes/nb_saes, overall_detection_rate_saes, nb_saes))\n",
    "            rec['overall'] = float(overall_detection_rate_saes/nb_saes)\n",
    "            to_csv.append(rec)\n",
    "\n",
    "            # No adversarial examples for training for the current detection methods.\n",
    "            # X_sae_all, Y_sae_all = self.get_sae_testing_data()\n",
    "            print (\"### Excluding FAEs:\")\n",
    "            if FLAGS.detection_train_test_mode:\n",
    "                X_nfae_all, Y_nfae_all = self.get_all_non_fae_testing_data()\n",
    "            else:\n",
    "                X_nfae_all, Y_nfae_all = self.get_all_non_fae_data()\n",
    "            Y_pred, Y_pred_score = detector.test(X_nfae_all)\n",
    "            _, tpr, _, tp, ap = evalulate_detection_test(Y_nfae_all, Y_pred)\n",
    "            fprs, tprs, thresholds = roc_curve(Y_nfae_all, Y_pred_score)\n",
    "\n",
    "            # print (\"threshold\\tfpr\\ttpr\")\n",
    "            # for i, threshold  in enumerate(thresholds):\n",
    "            #     print (\"%.4f\\t%.4f\\t%.4f\" % (threshold, fprs[i], tprs[i]))\n",
    "\n",
    "            roc_auc = auc(fprs, tprs)\n",
    "            print (\"Overall TPR: %f\\tROC-AUC: %f\" % (tpr, roc_auc))\n",
    "\n",
    "            # FAEs\n",
    "            if FLAGS.detection_train_test_mode:\n",
    "                X_fae, Y_fae = self.get_fae_testing_data()\n",
    "            else:\n",
    "                X_fae, Y_fae = self.get_fae_data()\n",
    "            Y_test_pred, Y_test_pred_score = detector.test(X_fae)\n",
    "            _, tpr, _, tp, ap = evalulate_detection_test(Y_fae, Y_test_pred)\n",
    "            print (\"Overall detection rate on FAEs: %.4f \\t %3d/%3d\" % (tpr, tp, ap))\n",
    "        # print(csv_fpath,fieldnames)\n",
    "        write_to_csv(to_csv, csv_fpath, fieldnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if FLAGS.detection != '':\n",
    "#     # from detections.base import DetectionEvaluator\n",
    "\n",
    "#     result_folder_detection = os.path.join(FLAGS.result_folder, \"detection\")\n",
    "#     csv_fname = \"%s_attacks_%s_detection.csv\" % (task_id, attack_string_hash)\n",
    "#     de = DetectionEvaluator(model, result_folder_detection, csv_fname, FLAGS.dataset_name)\n",
    "#     Y_test_all_pred = model.predict(X_test_all)\n",
    "#     attack_string_list = filter(lambda x:len(x)>0, FLAGS.attacks.lower().split(';'))\n",
    "#     # de.build_detection_dataset(X_test_all, Y_test_all, Y_test_all_pred, selected_idx, X_test_adv_discretized_list, Y_test_adv_discretized_pred_list, attack_string_list, attack_string_hash, FLAGS.clip, Y_test_target_next, Y_test_target_ll)\n",
    "#     de.build_detection_dataset(X_test_all, Y_test_all, Y_test_all_pred, selected_idx, X_test_adv_discretized_list, Y_test_adv_discretized_pred_list,\n",
    "#                                 FLAGS.attacks, attack_string_hash, FLAGS.clip, Y_test_target_next, Y_test_target_ll)\n",
    "#     de.evaluate_detections(FLAGS.detection,X_test_all,Y_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "anchor (InputLayer)              (None, 64, 64, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "positive (InputLayer)            (None, 64, 64, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "negative (InputLayer)            (None, 64, 64, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "Embedding (Model)                (None, 64)            1063856     anchor[0][0]                     \n",
      "                                                                   positive[0][0]                   \n",
      "                                                                   negative[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                (None,)               0           Embedding[1][0]                  \n",
      "                                                                   Embedding[2][0]                  \n",
      "                                                                   Embedding[3][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,063,856\n",
      "Trainable params: 1,044,864\n",
      "Non-trainable params: 18,992\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import backend as K\n",
    "GTSRB_8_Dense_model = keras.models.Model(inputs = model.input, outputs = model.layers[156].output)\n",
    "\n",
    "def identity_loss(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "def triplet_loss(x, alpha = 1):\n",
    "# def triplet_loss(x, alpha = 10):\n",
    "# def triplet_loss(x, alpha = 30):\n",
    "    # Triplet Loss function.\n",
    "    anchor,positive,negative = x\n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    loss = K.maximum(basic_loss,0.0)\n",
    "    return loss\n",
    "\n",
    "anchor_input   = layers.Input((64, 64, 3),name=\"anchor\"  )\n",
    "positive_input = layers.Input((64, 64, 3),name=\"positive\")    \n",
    "negative_input = layers.Input((64, 64, 3),name=\"negative\") \n",
    "# embedding_network = CIFAR_10_Dense_model   \n",
    "\n",
    "# tower_1 = embedding_network(anchor_input)\n",
    "normal_layer_1 = keras.layers.BatchNormalization(name=\"bat_1\")(GTSRB_8_Dense_model.output)\n",
    "# normal_layer_1 = layers.Dense(512, activation=\"relu\")(normal_layer_1)\n",
    "# normal_layer_1 = keras.layers.BatchNormalization(name=\"bat_2\")(normal_layer_1)\n",
    "normal_layer_1 = layers.Dense(64, activation=\"relu\")(normal_layer_1)\n",
    "\n",
    "embedding = keras.models.Model(GTSRB_8_Dense_model.input, normal_layer_1, name=\"Embedding\")\n",
    "\n",
    "A = embedding(anchor_input  )\n",
    "P = embedding(positive_input)\n",
    "N = embedding(negative_input)\n",
    "\n",
    "loss = layers.Lambda(triplet_loss)([A, P, N])\n",
    "\n",
    "siamese_network = keras.models.Model(\n",
    "    inputs=[anchor_input, positive_input, negative_input], outputs=loss )\n",
    "# siamese_network.load_weights(\"Triplets/ep_alpha1_01_los1.056_GTSRB_Triplets_adv.h5\")\n",
    "siamese_network.load_weights(\"C:/Users/ahmad/Desktop/JupyterFilesAUB/GTSRB_dataset/Siamese_Triplets/ep_alpha1_01_los0.206_GTSRB_Triplets_adv.h5\")\n",
    "siamese_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8140\n"
     ]
    }
   ],
   "source": [
    "X_train      = []\n",
    "X_train_orig = []\n",
    "Y_train      = []\n",
    "classes_str  = ['00000','00001','00002','00003',\n",
    "                '00004','00005','00007','00008']\n",
    "dim = 64\n",
    "cur_path = 'C:/Users/ahmad/Desktop/JupyterFilesAUB/GTSRB_dataset/Final_Training/Train_Images_Edit_Ver' \n",
    "q = -1\n",
    "for i in classes_str: \n",
    "  q+=1\n",
    "  path = os. path.join(cur_path, i) \n",
    "  images = os.listdir(path) \n",
    "  for a in images: \n",
    "    try: \n",
    "      # image1 = cv2.cvtColor(cv2.imread(path + '/'+ a), cv2.COLOR_BGR2GRAY)\n",
    "      # image1 = cv2.resize(image1, (dim, dim))\n",
    "      image = cv2.cvtColor(cv2.imread(path + '/'+ a), cv2.COLOR_BGR2RGB)\n",
    "      image = cv2.resize(image, (dim, dim)) \n",
    "      X_train     .append(image) \n",
    "      # X_train_orig.append(image1)\n",
    "      Y_train     .append(q) \n",
    "    except: \n",
    "      print(\"Error loading image\"+path + '/'+ a) \n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "print(len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedClahe_Filtering...\n"
     ]
    }
   ],
   "source": [
    "train_images = medfilter(X_train)\n",
    "train_images = train_images.astype(np.float32)/255\n",
    "train_labels = Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "# import json \n",
    "from keras.layers import BatchNormalization\n",
    "from numpy.linalg import norm\n",
    "IMG_CHANNELS = 1\n",
    "dim          = 64\n",
    "IMG_WIDTH    = dim\n",
    "IMG_HEIGHT   = dim\n",
    "#Build the model\n",
    "inputs = keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "# s = keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "#Contraction path\n",
    "c1 = keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "b1 = BatchNormalization()(c1)\n",
    "c1 = keras.layers.Dropout(0.1)(b1)\n",
    "c1 = keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "b1 = BatchNormalization()(c1)\n",
    "p1 = keras.layers.MaxPooling2D((2, 2))(b1)\n",
    "\n",
    "c2 = keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "b2 = BatchNormalization()(c2)\n",
    "c2 = keras.layers.Dropout(0.1)(b2)\n",
    "c2 = keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "b2 = BatchNormalization()(c2)\n",
    "p2 = keras.layers.MaxPooling2D((2, 2))(b2)\n",
    "\n",
    "c3 = keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "b3 = BatchNormalization()(c3)\n",
    "c3 = keras.layers.Dropout(0.2)(b3)\n",
    "c3 = keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "b3 = BatchNormalization()(c3)\n",
    "p3 = keras.layers.MaxPooling2D((2, 2))(b3)\n",
    "\n",
    "c4 = keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "b4 = BatchNormalization()(c4)\n",
    "c4 = keras.layers.Dropout(0.2)(b4)\n",
    "c4 = keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "b4 = BatchNormalization()(c4)\n",
    "p4 = keras.layers.MaxPooling2D(pool_size=(2, 2))(b4)\n",
    "\n",
    "c5 = keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "b5 = BatchNormalization()(c5)\n",
    "c5 = keras.layers.Dropout(0.3)(b5)\n",
    "c5 = keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "b5 = BatchNormalization()(c5)\n",
    "\n",
    "#Expansive path \n",
    "u6 = keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(b5)\n",
    "u6 = keras.layers.concatenate([u6, c4])\n",
    "c6 = keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "b6 = BatchNormalization()(c6)\n",
    "c6 = keras.layers.Dropout(0.2)(b6)\n",
    "c6 = keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "b6 = BatchNormalization()(c6)\n",
    "\n",
    "u7 = keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(b6)\n",
    "u7 = keras.layers.concatenate([u7, c3])\n",
    "c7 = keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "b7 = BatchNormalization()(c7)\n",
    "c7 = keras.layers.Dropout(0.2)(b7)\n",
    "c7 = keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "b7 = BatchNormalization()(c7)\n",
    "\n",
    "u8 = keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(b7)\n",
    "u8 = keras.layers.concatenate([u8, c2])\n",
    "c8 = keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "b8 = BatchNormalization()(c8)\n",
    "c8 = keras.layers.Dropout(0.1)(b8)\n",
    "c8 = keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "b8 = BatchNormalization()(c8)\n",
    "\n",
    "u9 = keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(b8)\n",
    "u9 = keras.layers.concatenate([u9, c1], axis=3)\n",
    "c9 = keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "b9 = BatchNormalization()(c9)\n",
    "c9 = keras.layers.Dropout(0.1)(b9)\n",
    "c9 = keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "b9 = BatchNormalization()(c9)\n",
    "\n",
    "outputs = keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(b9)\n",
    "\n",
    "graph_U_Net = tf.get_default_graph()\n",
    "with graph_U_Net.as_default():\n",
    "    session_U_Net = tf.Session()\n",
    "    with session_U_Net.as_default():\n",
    "        U_Net_Model = keras.models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    U_Net_Model.load_weights(\"C:/Users/ahmad/Desktop/JupyterFilesAUB/GTSRB_dataset/checkpointsUnet/allTset_ep_15_acc0.95195_GTSRB_UNet.h5\")\n",
    "    U_Net_Model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "###############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\spd\\lib\\site-packages\\sklearn\\base.py:315: UserWarning: Trying to unpickle estimator OneClassSVM from version 1.3.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "filename = 'C:/Users/ahmad/Desktop/JupyterFilesAUB/GTSRB_dataset/checkpointsSVM/one_svm_model_GTSRB.sav'\n",
    "OC_SVM_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X_test,Y_test,threshold, flag):\n",
    "        adv_cls = 10\n",
    "        x_adv_SVM = np.zeros(len(Y_test))\n",
    "        X_test_ = []\n",
    "        for img in X_test:\n",
    "            # image = cv2.resize(img, (dim,dim)) #64*64*1 Images\n",
    "            img_uint8 = np.clip(np.rint(img * 255), 0, 255).astype(np.uint8)\n",
    "            image = cv2.cvtColor(img_uint8,cv2.COLOR_RGB2GRAY)\n",
    "            image = np.expand_dims(image, axis=2)\n",
    "            X_test_.append(image)\n",
    "        X_test_ = np.array(X_test_)\n",
    "        X_test_U = X_test_/255.\n",
    "        X_test_mask           = U_Net_Model.predict(X_test_U,verbose=0)\n",
    "        X_test_preds_mask_t   = (X_test_mask > 0.5).astype(np.uint8)\n",
    "        X_test_masks          = np.array(X_test_preds_mask_t)\n",
    "        adv_labels_SVM = x_adv_SVM\n",
    "        X_adv_OCsvm = X_test_masks.reshape((len(X_test_masks), -1))\n",
    "        result = OC_SVM_model.predict(X_adv_OCsvm )\n",
    "        oc_indices = np.where(result==-1)[0]\n",
    "        adv_labels_SVM[oc_indices] = adv_cls\n",
    "#############################################################\n",
    "        Y_test  = np.array(Y_test )\n",
    "        X_test_orig       = []\n",
    "        for img in X_test:\n",
    "            img_uint8 = np.clip(np.rint(img * 255), 0, 255).astype(np.uint8)\n",
    "            X_test_orig.append(img_uint8)\n",
    "        X_test_orig = medfilter(X_test_orig)\n",
    "        X_test_orig = np.array (X_test_orig)\n",
    "        # X_test_orig = X_test_orig.reshape(X_test_orig.shape[0],X_test_orig.shape[1],X_test_orig.shape[2],1)\n",
    "        # X_test_orig  = X_test_orig.astype(np.float32)/255\n",
    "        # print(X_test_orig.shape)\n",
    "        num_classes_clean   = max(train_labels) + 1\n",
    "        digit_indices_clean = [np.where(np.array(train_labels) == i)[0] for i in range(int(num_classes_clean))]\n",
    "        siamese_labels_1    = []\n",
    "        for idx1 in range(len(X_test_orig)):\n",
    "            # add a matching example\n",
    "            x1     = X_test_orig [idx1]\n",
    "            label1 = Y_test      [idx1]\n",
    "            x1     = x1/255.\n",
    "            idx2   = random.choice(digit_indices_clean[label1])\n",
    "            x2     = train_images[idx2]\n",
    "            idx3   = random.choice(digit_indices_clean[label1])\n",
    "            x3     = train_images[idx3]#Two_Sample\n",
    "            anchor   = embedding.predict(np.expand_dims(x1, axis=0),verbose = 0)\n",
    "            positive = embedding.predict(np.expand_dims(x2, axis=0),verbose = 0)\n",
    "            positive3 = embedding.predict(np.expand_dims(x3, axis=0),verbose = 0)#Two_Sample\n",
    "\n",
    "            anchor   = np.reshape(anchor  ,64)\n",
    "            positive = np.reshape(positive,64)\n",
    "            positive3 = np.reshape(positive3,64)#Two_Sample\n",
    "            pos_dist = np.dot(anchor,positive)/(norm(anchor)*norm(positive))\n",
    "            pos_dist3 = np.dot(anchor,positive3)/(norm(anchor)*norm(positive3))#Two_Sample\n",
    "            pos_dist_final = min(pos_dist,pos_dist3)#Two_Sample\n",
    "\n",
    "            siamese_labels_1.append(pos_dist_final)#Two_Sample\n",
    "            # siamese_labels_1.append(pos_dist)\n",
    "            # print(pos_dist)\n",
    "\n",
    "        print(len(siamese_labels_1))\n",
    "        print(siamese_labels_1[0])\n",
    "        if len(siamese_labels_1) !=0:\n",
    "            x_ = np.zeros(len(siamese_labels_1))\n",
    "            x_[np.where(np.array(siamese_labels_1)>threshold)[0]] = 1\n",
    "            res = len(np.where(x_==0)[0])/len(siamese_labels_1)\n",
    "            print(\"Siamese_Detection\",res,\"%\")\n",
    "            x_[oc_indices] = 0     #SVM Detection\n",
    "            return x_== 0 # inverse logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Segmentation\n",
      "['detector', 'threshold', 'fpr', 'fpr_all_test_clean', 'Accuracy_all_test_clean', 'fgsm?eps=0.0156', 'bim?eps=0.008&eps_iter=0.0012', 'carlinili?targeted=next&batch_size=16&confidence=5', 'carlinili?targeted=ll&batch_size=16&confidence=5', 'deepfool?overshoot=10', 'carlinil2?targeted=next&batch_size=16&max_iterations=1000&confidence=5', 'carlinil2?targeted=ll&batch_size=16&max_iterations=1000&confidence=5', 'carlinil0?targeted=next&batch_size=16&confidence=5', 'carlinil0?targeted=ll&batch_size=16&confidence=5', 'jsma?targeted=next', 'jsma?targeted=ll', 'overall']\n",
      "MedClahe_Filtering...\n",
      "96\n",
      "0.9911359\n",
      "Siamese_Detection 0.020833333333333332 %\n",
      "Detector: Siamese_detector_Med_Clahe_SVM\n",
      "Accuracy: 0.947917\tTPR: nan\tFPR: 0.052083\t\n",
      "MedClahe_Filtering...\n",
      "3142\n",
      "0.99378955\n",
      "Siamese_Detection 0.027052832590706555 %\n",
      "Accuracy_all_test:0.953  FPR_all_test:0.047 For all TestSet\n",
      "MedClahe_Filtering...\n",
      "74\n",
      "0.113714546\n",
      "Siamese_Detection 1.0 %\n",
      "Detection rate on SAEs: 1.0000 \t  74/ 74 \t fgsm?eps=0.0156\n",
      "overall_detection_rate_saes/nb_saes: 74/74\n",
      "MedClahe_Filtering...\n",
      "83\n",
      "0.0752737\n",
      "Siamese_Detection 1.0 %\n",
      "Detection rate on SAEs: 1.0000 \t  83/ 83 \t bim?eps=0.008&eps_iter=0.0012\n",
      "overall_detection_rate_saes/nb_saes: 157/157\n",
      "Yes Next\n",
      "MedClahe_Filtering...\n",
      "96\n",
      "0.3192922\n",
      "Siamese_Detection 1.0 %\n",
      "Detection rate on SAEs: 1.0000 \t  96/ 96 \t carlinili?targeted=next&batch_size=16&confidence=5\n",
      "overall_detection_rate_saes/nb_saes: 253/253\n",
      "Yes LL\n",
      "MedClahe_Filtering...\n",
      "96\n",
      "0.36634806\n",
      "Siamese_Detection 1.0 %\n",
      "Detection rate on SAEs: 1.0000 \t  96/ 96 \t carlinili?targeted=ll&batch_size=16&confidence=5\n",
      "overall_detection_rate_saes/nb_saes: 349/349\n",
      "MedClahe_Filtering...\n",
      "96\n",
      "0.15348688\n",
      "Siamese_Detection 1.0 %\n",
      "Detection rate on SAEs: 1.0000 \t  96/ 96 \t deepfool?overshoot=10\n",
      "overall_detection_rate_saes/nb_saes: 445/445\n",
      "Yes Next\n",
      "MedClahe_Filtering...\n",
      "96\n",
      "0.32816362\n",
      "Siamese_Detection 1.0 %\n",
      "Detection rate on SAEs: 1.0000 \t  96/ 96 \t carlinil2?targeted=next&batch_size=16&max_iterations=1000&confidence=5\n",
      "overall_detection_rate_saes/nb_saes: 541/541\n",
      "Yes LL\n",
      "MedClahe_Filtering...\n",
      "96\n",
      "0.35421422\n",
      "Siamese_Detection 1.0 %\n",
      "Detection rate on SAEs: 1.0000 \t  96/ 96 \t carlinil2?targeted=ll&batch_size=16&max_iterations=1000&confidence=5\n",
      "overall_detection_rate_saes/nb_saes: 637/637\n",
      "Yes Next\n",
      "MedClahe_Filtering...\n",
      "96\n",
      "0.36330032\n",
      "Siamese_Detection 1.0 %\n",
      "Detection rate on SAEs: 1.0000 \t  96/ 96 \t carlinil0?targeted=next&batch_size=16&confidence=5\n",
      "overall_detection_rate_saes/nb_saes: 733/733\n",
      "Yes LL\n",
      "MedClahe_Filtering...\n",
      "96\n",
      "0.38487408\n",
      "Siamese_Detection 1.0 %\n",
      "Detection rate on SAEs: 1.0000 \t  96/ 96 \t carlinil0?targeted=ll&batch_size=16&confidence=5\n",
      "overall_detection_rate_saes/nb_saes: 829/829\n",
      "Yes Next\n",
      "MedClahe_Filtering...\n",
      "96\n",
      "0.33836904\n",
      "Siamese_Detection 1.0 %\n",
      "Detection rate on SAEs: 1.0000 \t  96/ 96 \t jsma?targeted=next\n",
      "overall_detection_rate_saes/nb_saes: 925/925\n",
      "Yes LL\n",
      "MedClahe_Filtering...\n",
      "93\n",
      "0.41426125\n",
      "Siamese_Detection 1.0 %\n",
      "Detection rate on SAEs: 1.0000 \t  93/ 93 \t jsma?targeted=ll\n",
      "overall_detection_rate_saes/nb_saes: 1018/1018\n",
      "1018\n",
      "Overall detection rate on SAEs: 1.000000 (1018/1018)\n",
      "MedClahe_Filtering...\n",
      "38\n",
      "0.9963282\n",
      "Siamese_Detection 0.13157894736842105 %\n",
      "Overall detection rate on FAEs: 0.1316 \t   5/ 38\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello Segmentation\")\n",
    "# detector_names = [ele.strip() for ele in params_str.split(';') if ele.strip()!= '']\n",
    "attack_names = FLAGS.attacks.lower().split(';')\n",
    "dataset_name = \"GTSRB_8\"\n",
    "# detector_name = \"Siamese_detector_Two_Sample_Med_Clahe_SVM\"\n",
    "# csv_fpath = \"./Siamese_detection_Two_Sample_Med_Clahe_SVM_%s_saes_05_thresh.csv\" % dataset_name \n",
    "detector_name = \"Siamese_detector_Med_Clahe_SVM\"\n",
    "csv_fpath = \"./Siamese_detection_Med_Clahe_SVM_%s_saes_05_thresh.csv\" % dataset_name \n",
    "fieldnames = ['detector', 'threshold', 'fpr','fpr_all_test_clean','Accuracy_all_test_clean'] + list(attack_names) + ['overall']\n",
    "print(fieldnames)\n",
    "to_csv = []\n",
    "threshold = 0.9\n",
    "flag = 0\n",
    "\n",
    "Y_test_pred  = test(X_test_all[:len(selected_idx)],np.argmax(Y_test_all[:len(selected_idx)],axis=1),threshold, flag)\n",
    "X_test_zeros = np.zeros(np.array(Y_test_pred).shape) \n",
    "accuracy, tpr, fpr, tp, ap = evalulate_detection_test(X_test_zeros, Y_test_pred)\n",
    "# fprs, tprs, thresholds = roc_curve(Y_test, Y_test_pred_score)\n",
    "# roc_auc = auc(fprs, tprs)\n",
    "\n",
    "print (\"Detector: %s\" % detector_name)\n",
    "print (\"Accuracy: %f\\tTPR: %f\\tFPR: %f\\t\" % (accuracy, tpr, fpr))\n",
    "\n",
    "Y_test_pred_t = test(X_test_all,np.argmax(Y_test_all,axis=1),threshold, flag)\n",
    "# print(Y_test_pred_t[0], \"Hello Boy\" )\n",
    "Y_test_thresh = np.zeros(np.array(np.argmax(Y_test_all,axis=1)).shape) \n",
    "accuracy_all, tpr_all, fpr_all, tp_all, ap_all = evalulate_detection_test(Y_test_thresh, Y_test_pred_t)\n",
    "print(\"Accuracy_all_test:%.3f\" % accuracy_all,\" FPR_all_test:%.3f\" % fpr_all,\"For all TestSet\")\n",
    "flag = 1\n",
    "rec  = {}\n",
    "rec['detector'] = detector_name\n",
    "rec['threshold'] = threshold\n",
    "rec['fpr'] = fpr\n",
    "rec['Accuracy_all_test_clean'] = accuracy_all\n",
    "rec['fpr_all_test_clean'] = fpr_all\n",
    "overall_detection_rate_saes = 0\n",
    "nb_saes = 0\n",
    "\n",
    "count = 0\n",
    "y_check_non = []\n",
    "x_check_non = []\n",
    "for attack_name in attack_names:\n",
    "    if 'targeted=ll' in attack_name:\n",
    "        print(\"Yes LL\")\n",
    "        Y_adv_orig  = np.argmax(Y_test_adv_discretized_pred_list[count],axis=1)\n",
    "        adv_indeces = np.where (Y_adv_orig==np.argmax(Y_test_target_ll, axis=1))[0]\n",
    "        y_check     = Y_adv_orig[adv_indeces]\n",
    "        Y_test_pred       = test(np.array(X_test_adv_discretized_list[count])[adv_indeces],\n",
    "                                     y_check,threshold, flag)\n",
    "        non_adv_indeces = np.where (Y_adv_orig!=np.argmax(Y_test_target_ll, axis=1))[0]\n",
    "        if len(non_adv_indeces)>0:\n",
    "            y_check_non.append(Y_adv_orig[non_adv_indeces])\n",
    "            x_check_non.append(np.array(X_test_adv_discretized_list[count])[non_adv_indeces])\n",
    "        count+=1\n",
    "    elif 'targeted=next' in attack_name:\n",
    "        print(\"Yes Next\")\n",
    "        Y_adv_orig  = np.argmax(Y_test_adv_discretized_pred_list[count],axis=1)\n",
    "        adv_indeces = np.where (Y_adv_orig==np.argmax(Y_test_target_next, axis=1))[0]\n",
    "        y_check     = Y_adv_orig[adv_indeces]\n",
    "        Y_test_pred       = test(np.array(X_test_adv_discretized_list[count])[adv_indeces],\n",
    "                                   y_check ,threshold, flag)\n",
    "        non_adv_indeces = np.where (Y_adv_orig!=np.argmax(Y_test_target_next, axis=1))[0]\n",
    "        if len(non_adv_indeces)>0:\n",
    "            y_check_non.append(Y_adv_orig[non_adv_indeces])\n",
    "            x_check_non.append(np.array(X_test_adv_discretized_list[count])[non_adv_indeces])\n",
    "        count+=1\n",
    "    else:\n",
    "        Y_adv_orig  = np.argmax(Y_test_adv_discretized_pred_list[count],axis=1)\n",
    "        adv_indeces = np.where (Y_adv_orig!=np.argmax(Y_test_all[selected_idx], axis=1))[0]\n",
    "        y_check     = Y_adv_orig[adv_indeces]\n",
    "        Y_test_pred = test(np.array(X_test_adv_discretized_list[count])[adv_indeces],\n",
    "                                    y_check,threshold, flag)\n",
    "        non_adv_indeces = np.where (Y_adv_orig==np.argmax(Y_test_all[selected_idx], axis=1))[0]\n",
    "        if len(non_adv_indeces)>0:\n",
    "            y_check_non.append(Y_adv_orig[non_adv_indeces])\n",
    "            x_check_non.append(np.array(X_test_adv_discretized_list[count])[non_adv_indeces])\n",
    "        count+=1\n",
    "    Y_sae             = np.ones(np.array(Y_test_pred).shape) \n",
    "    _, tpr, _, tp, ap = evalulate_detection_test(Y_sae, Y_test_pred)\n",
    "    print (\"Detection rate on SAEs: %.4f \\t %3d/%3d \\t %s\" % (tpr, tp, ap, attack_name))\n",
    "    overall_detection_rate_saes += tpr * len(Y_sae)\n",
    "    nb_saes += len(Y_sae)\n",
    "    rec[attack_name] = tpr\n",
    "    print (\"overall_detection_rate_saes/nb_saes: %d/%d\" % (overall_detection_rate_saes, nb_saes))\n",
    "print(nb_saes)\n",
    "print (\"Overall detection rate on SAEs: %f (%d/%d)\" % (overall_detection_rate_saes/nb_saes, overall_detection_rate_saes, nb_saes))\n",
    "rec['overall'] = float(overall_detection_rate_saes/nb_saes)\n",
    "to_csv.append(rec)\n",
    "y_check_non = np.array(list(itertools.chain(*y_check_non)))\n",
    "x_check_non = np.array(list(itertools.chain(*x_check_non)))\n",
    "#FAEs\n",
    "Y_test_pred = test(x_check_non,\n",
    "                                   y_check_non ,threshold, flag)\n",
    "Y_fae       = np.ones(np.array(y_check_non).shape) \n",
    "_, tpr, _, tp, ap = evalulate_detection_test(Y_fae, Y_test_pred)\n",
    "print (\"Overall detection rate on FAEs: %.4f \\t %3d/%3d\" % (tpr, tp, ap))\n",
    "write_to_csv(to_csv, csv_fpath, fieldnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Segmentation\n",
      "siamese_0: Compiled\n",
      "siamese_1: Compiled\n",
      "siamese_2: Compiled\n",
      "siamese_3: Compiled\n",
      "siamese_4: Compiled\n",
      "siamese_5: Compiled\n",
      "siamese_6: Compiled\n",
      "siamese_7: Compiled\n",
      "MedClahe_Filtering...\n",
      "8140\n",
      "['detector', 'threshold', 'fpr', 'fpr_all_test_clean', 'Accuracy_all_test_clean', 'fgsm?eps=0.3', 'overall']\n",
      "Train is Done\n",
      "MedClahe_Filtering...\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_0\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_0\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_7\n",
      "Siamese_Detection 0.0 %\n",
      "Detector: Siamese_detector\n",
      "Accuracy: 1.000000\tTPR: nan\tFPR: 0.000000\t\n",
      "MedClahe_Filtering...\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_0\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_0\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_0\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_0\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_0\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_0\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_0\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_0\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_0\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_0\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_0\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_0\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_0\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_0\n",
      "siamese_6\n",
      "siamese_0\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_0\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_0\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_0\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_7\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_0\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_0\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_0\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_0\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_0\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_0\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_0\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_7\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_0\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_0\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_0\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_0\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_0\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_0\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_0\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_0\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_0\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_0\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_0\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_0\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_0\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_0\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_0\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_0\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_0\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_0\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_0\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_0\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_0\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_0\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_0\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_0\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_0\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_0\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_7\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_0\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_0\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_0\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_0\n",
      "siamese_2\n",
      "siamese_0\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_7\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_0\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_0\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_0\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_3\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_6\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_1\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_3\n",
      "siamese_6\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_6\n",
      "siamese_7\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_2\n",
      "siamese_6\n",
      "siamese_4\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_0\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_5\n",
      "siamese_6\n",
      "siamese_3\n",
      "siamese_5\n",
      "siamese_2\n",
      "siamese_4\n",
      "siamese_1\n",
      "siamese_7\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_1\n",
      "siamese_2\n",
      "siamese_1\n",
      "siamese_4\n",
      "siamese_3\n",
      "siamese_7\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "siamese_2\n",
      "Siamese_Detection 0.009866327180140038 %\n",
      "Accuracy_all_test:0.990  FPR_all_test:0.010 For all TestSet\n",
      "MedClahe_Filtering...\n",
      "siamese_2\n",
      "[[2.257475e-08]]\n",
      "siamese_2\n",
      "[[1.5556987e-08]]\n",
      "siamese_2\n",
      "[[3.8333834e-08]]\n",
      "siamese_2\n",
      "[[1.1211203e-07]]\n",
      "siamese_2\n",
      "[[2.3186695e-08]]\n",
      "siamese_2\n",
      "[[3.4960027e-07]]\n",
      "siamese_2\n",
      "[[6.544154e-08]]\n",
      "siamese_2\n",
      "[[9.406535e-09]]\n",
      "siamese_2\n",
      "[[1.0510215e-08]]\n",
      "siamese_2\n",
      "[[2.434782e-07]]\n",
      "siamese_2\n",
      "[[1.2488371e-07]]\n",
      "siamese_2\n",
      "[[2.6560112e-08]]\n",
      "siamese_2\n",
      "[[2.1558716e-07]]\n",
      "siamese_2\n",
      "[[3.4435708e-08]]\n",
      "siamese_2\n",
      "[[1.3605925e-08]]\n",
      "siamese_2\n",
      "[[3.4223103e-08]]\n",
      "siamese_2\n",
      "[[1.8243691e-08]]\n",
      "siamese_2\n",
      "[[1.443291e-08]]\n",
      "siamese_2\n",
      "[[1.3895111e-07]]\n",
      "siamese_2\n",
      "[[1.331467e-08]]\n",
      "siamese_2\n",
      "[[8.29586e-08]]\n",
      "siamese_2\n",
      "[[3.28207e-08]]\n",
      "siamese_2\n",
      "[[1.1913e-07]]\n",
      "siamese_2\n",
      "[[3.368173e-08]]\n",
      "siamese_2\n",
      "[[2.7275725e-08]]\n",
      "siamese_2\n",
      "[[2.8924584e-08]]\n",
      "siamese_2\n",
      "[[2.0507127e-07]]\n",
      "siamese_2\n",
      "[[4.4501455e-08]]\n",
      "siamese_2\n",
      "[[3.2686824e-08]]\n",
      "siamese_2\n",
      "[[3.7905373e-08]]\n",
      "siamese_2\n",
      "[[7.647827e-08]]\n",
      "siamese_2\n",
      "[[2.2935847e-08]]\n",
      "siamese_2\n",
      "[[2.586668e-08]]\n",
      "siamese_2\n",
      "[[1.2566733e-07]]\n",
      "siamese_2\n",
      "[[1.8006492e-07]]\n",
      "siamese_2\n",
      "[[4.0775497e-08]]\n",
      "siamese_2\n",
      "[[3.8781184e-08]]\n",
      "siamese_2\n",
      "[[3.841376e-08]]\n",
      "siamese_2\n",
      "[[1.0018955e-08]]\n",
      "siamese_0\n",
      "[[1.909579e-08]]\n",
      "siamese_2\n",
      "[[5.7055505e-08]]\n",
      "siamese_2\n",
      "[[1.39914444e-08]]\n",
      "siamese_2\n",
      "[[1.800317e-08]]\n",
      "siamese_2\n",
      "[[7.195796e-08]]\n",
      "siamese_2\n",
      "[[1.500207e-08]]\n",
      "siamese_2\n",
      "[[4.9727692e-08]]\n",
      "siamese_2\n",
      "[[3.0101603e-08]]\n",
      "siamese_2\n",
      "[[2.4739048e-08]]\n",
      "siamese_2\n",
      "[[2.7034216e-07]]\n",
      "siamese_2\n",
      "[[2.7961931e-08]]\n",
      "siamese_2\n",
      "[[3.937868e-08]]\n",
      "siamese_2\n",
      "[[4.7902713e-08]]\n",
      "siamese_2\n",
      "[[2.7467113e-08]]\n",
      "siamese_2\n",
      "[[2.0885945e-07]]\n",
      "siamese_2\n",
      "[[8.63952e-08]]\n",
      "siamese_2\n",
      "[[4.506512e-07]]\n",
      "siamese_2\n",
      "[[3.9237247e-07]]\n",
      "siamese_2\n",
      "[[1.2795674e-07]]\n",
      "siamese_2\n",
      "[[1.1474242e-08]]\n",
      "siamese_2\n",
      "[[1.2641222e-07]]\n",
      "siamese_2\n",
      "[[2.1033031e-08]]\n",
      "siamese_2\n",
      "[[1.22752235e-08]]\n",
      "siamese_2\n",
      "[[1.3126459e-08]]\n",
      "siamese_2\n",
      "[[1.5042758e-08]]\n",
      "siamese_2\n",
      "[[6.24519e-08]]\n",
      "siamese_2\n",
      "[[3.5915065e-08]]\n",
      "siamese_2\n",
      "[[1.0729705e-07]]\n",
      "siamese_2\n",
      "[[1.0931645e-08]]\n",
      "siamese_2\n",
      "[[1.6056209e-08]]\n",
      "siamese_2\n",
      "[[7.540138e-08]]\n",
      "siamese_2\n",
      "[[1.02275e-08]]\n",
      "siamese_2\n",
      "[[2.7366062e-07]]\n",
      "siamese_2\n",
      "[[1.7793393e-08]]\n",
      "siamese_2\n",
      "[[1.5191972e-08]]\n",
      "siamese_2\n",
      "[[1.7220934e-08]]\n",
      "siamese_2\n",
      "[[3.819043e-08]]\n",
      "siamese_2\n",
      "[[1.4160535e-07]]\n",
      "siamese_2\n",
      "[[2.2339465e-08]]\n",
      "siamese_2\n",
      "[[1.9344261e-08]]\n",
      "siamese_2\n",
      "[[7.808789e-08]]\n",
      "siamese_2\n",
      "[[3.7175834e-08]]\n",
      "siamese_2\n",
      "[[3.77586e-08]]\n",
      "siamese_2\n",
      "[[2.4406516e-08]]\n",
      "siamese_2\n",
      "[[1.421246e-07]]\n",
      "Siamese_Detection 0.0 %\n",
      "Detection rate on SAEs: 0.0000 \t   0/ 84 \t fgsm?eps=0.3\n",
      "overall_detection_rate_saes/nb_saes: 0/84\n",
      "84\n",
      "Overall detection rate on SAEs: 0.000000 (0/84)\n",
      "MedClahe_Filtering...\n",
      "siamese_2\n",
      "[[6.177331e-08]]\n",
      "siamese_2\n",
      "[[1.3788433e-08]]\n",
      "siamese_2\n",
      "[[9.942471e-08]]\n",
      "siamese_2\n",
      "[[2.3184272e-07]]\n",
      "siamese_2\n",
      "[[1.82266e-07]]\n",
      "siamese_2\n",
      "[[4.7384294e-08]]\n",
      "siamese_2\n",
      "[[2.9005244e-08]]\n",
      "siamese_2\n",
      "[[1.5811803e-08]]\n",
      "siamese_2\n",
      "[[1.2813086e-07]]\n",
      "siamese_2\n",
      "[[2.3345699e-08]]\n",
      "siamese_2\n",
      "[[1.38573775e-08]]\n",
      "siamese_2\n",
      "[[1.04732525e-08]]\n",
      "Siamese_Detection 0.0 %\n",
      "Overall detection rate on FAEs: 0.0000 \t   0/ 12\n"
     ]
    }
   ],
   "source": [
    "# from Segmentation_detector_Siamese import Siamese_detector\n",
    "# print(\"Hello Segmentation\")\n",
    "# siamese_detector = Siamese_detector()\n",
    "# # detector_names = [ele.strip() for ele in params_str.split(';') if ele.strip()!= '']\n",
    "# attack_names = FLAGS.attacks.lower().split(';')\n",
    "# dataset_name = \"GTSRB_8\"\n",
    "# detector_name = \"Siamese_detector\"\n",
    "# csv_fpath = \"./Siamese_detection_%s_saes_3.csv\" % dataset_name \n",
    "# fieldnames = ['detector', 'threshold', 'fpr','fpr_all_test_clean','Accuracy_all_test_clean'] + list(attack_names) + ['overall']\n",
    "# print(fieldnames)\n",
    "# to_csv = []\n",
    "# threshold = 0.01\n",
    "# flag = 0\n",
    "# siamese_detector.train()\n",
    "# Y_test_pred  = siamese_detector.test(X_test_all[:len(selected_idx)],np.argmax(Y_test_all[:len(selected_idx)],axis=1),threshold, flag)\n",
    "# X_test_zeros = np.zeros(np.array(Y_test_pred).shape) \n",
    "# accuracy, tpr, fpr, tp, ap = evalulate_detection_test(X_test_zeros, Y_test_pred)\n",
    "# # fprs, tprs, thresholds = roc_curve(Y_test, Y_test_pred_score)\n",
    "# # roc_auc = auc(fprs, tprs)\n",
    "\n",
    "# print (\"Detector: %s\" % detector_name)\n",
    "# print (\"Accuracy: %f\\tTPR: %f\\tFPR: %f\\t\" % (accuracy, tpr, fpr))\n",
    "\n",
    "# Y_test_pred_t = siamese_detector.test(X_test_all,np.argmax(Y_test_all,axis=1),threshold, flag)\n",
    "# # print(Y_test_pred_t[0], \"Hello Boy\" )\n",
    "# Y_test_thresh = np.zeros(np.array(np.argmax(Y_test_all,axis=1)).shape) \n",
    "# accuracy_all, tpr_all, fpr_all, tp_all, ap_all = evalulate_detection_test(Y_test_thresh, Y_test_pred_t)\n",
    "# print(\"Accuracy_all_test:%.3f\" % accuracy_all,\" FPR_all_test:%.3f\" % fpr_all,\"For all TestSet\")\n",
    "# flag = 1\n",
    "# rec  = {}\n",
    "# rec['detector'] = detector_name\n",
    "# rec['threshold'] = None\n",
    "# rec['fpr'] = fpr\n",
    "# rec['Accuracy_all_test_clean'] = accuracy_all\n",
    "# rec['fpr_all_test_clean'] = fpr_all\n",
    "# overall_detection_rate_saes = 0\n",
    "# nb_saes = 0\n",
    "\n",
    "# count = 0\n",
    "# y_check_non = []\n",
    "# x_check_non = []\n",
    "# for attack_name in attack_names:\n",
    "#     if 'targeted=ll' in attack_name:\n",
    "#         print(\"Yes LL\")\n",
    "#         Y_adv_orig  = np.argmax(Y_test_adv_discretized_pred_list[count],axis=1)\n",
    "#         adv_indeces = np.where (Y_adv_orig==np.argmax(Y_test_target_ll, axis=1))[0]\n",
    "#         y_check     = Y_adv_orig[adv_indeces]\n",
    "#         Y_test_pred       = siamese_detector.test(np.array(X_test_adv_discretized_list[count])[adv_indeces],\n",
    "#                                      y_check,threshold, flag)\n",
    "#         non_adv_indeces = np.where (Y_adv_orig!=np.argmax(Y_test_target_ll, axis=1))[0]\n",
    "#         if len(non_adv_indeces)>0:\n",
    "#             y_check_non.append(Y_adv_orig[non_adv_indeces])\n",
    "#             x_check_non.append(np.array(X_test_adv_discretized_list[count])[non_adv_indeces])\n",
    "#         count+=1\n",
    "#     elif 'targeted=next' in attack_name:\n",
    "#         print(\"Yes Next\")\n",
    "#         Y_adv_orig  = np.argmax(Y_test_adv_discretized_pred_list[count],axis=1)\n",
    "#         adv_indeces = np.where (Y_adv_orig==np.argmax(Y_test_target_next, axis=1))[0]\n",
    "#         y_check     = Y_adv_orig[adv_indeces]\n",
    "#         Y_test_pred       = siamese_detector.test(np.array(X_test_adv_discretized_list[count])[adv_indeces],\n",
    "#                                    y_check ,threshold, flag)\n",
    "#         non_adv_indeces = np.where (Y_adv_orig!=np.argmax(Y_test_target_next, axis=1))[0]\n",
    "#         if len(non_adv_indeces)>0:\n",
    "#             y_check_non.append(Y_adv_orig[non_adv_indeces])\n",
    "#             x_check_non.append(np.array(X_test_adv_discretized_list[count])[non_adv_indeces])\n",
    "#         count+=1\n",
    "#     else:\n",
    "#         Y_adv_orig  = np.argmax(Y_test_adv_discretized_pred_list[count],axis=1)\n",
    "#         adv_indeces = np.where (Y_adv_orig!=np.argmax(Y_test_all[selected_idx], axis=1))[0]\n",
    "#         y_check     = Y_adv_orig[adv_indeces]\n",
    "#         Y_test_pred = siamese_detector.test(np.array(X_test_adv_discretized_list[count])[adv_indeces],\n",
    "#                                     y_check,threshold, flag)\n",
    "#         non_adv_indeces = np.where (Y_adv_orig==np.argmax(Y_test_all[selected_idx], axis=1))[0]\n",
    "#         if len(non_adv_indeces)>0:\n",
    "#             y_check_non.append(Y_adv_orig[non_adv_indeces])\n",
    "#             x_check_non.append(np.array(X_test_adv_discretized_list[count])[non_adv_indeces])\n",
    "#         count+=1\n",
    "#     Y_sae             = np.ones(np.array(Y_test_pred).shape) \n",
    "#     _, tpr, _, tp, ap = evalulate_detection_test(Y_sae, Y_test_pred)\n",
    "#     print (\"Detection rate on SAEs: %.4f \\t %3d/%3d \\t %s\" % (tpr, tp, ap, attack_name))\n",
    "#     overall_detection_rate_saes += tpr * len(Y_sae)\n",
    "#     nb_saes += len(Y_sae)\n",
    "#     rec[attack_name] = tpr\n",
    "#     print (\"overall_detection_rate_saes/nb_saes: %d/%d\" % (overall_detection_rate_saes, nb_saes))\n",
    "# print(nb_saes)\n",
    "# print (\"Overall detection rate on SAEs: %f (%d/%d)\" % (overall_detection_rate_saes/nb_saes, overall_detection_rate_saes, nb_saes))\n",
    "# rec['overall'] = float(overall_detection_rate_saes/nb_saes)\n",
    "# to_csv.append(rec)\n",
    "# y_check_non = np.array(list(itertools.chain(*y_check_non)))\n",
    "# x_check_non = np.array(list(itertools.chain(*x_check_non)))\n",
    "# #FAEs\n",
    "# Y_test_pred = siamese_detector.test(x_check_non,\n",
    "#                                    y_check_non ,threshold, flag)\n",
    "# Y_fae       = np.ones(np.array(y_check_non).shape) \n",
    "# _, tpr, _, tp, ap = evalulate_detection_test(Y_fae, Y_test_pred)\n",
    "# print (\"Overall detection rate on FAEs: %.4f \\t %3d/%3d\" % (tpr, tp, ap))\n",
    "# write_to_csv(to_csv, csv_fpath, fieldnames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
